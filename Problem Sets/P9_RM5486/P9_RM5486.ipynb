{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUxdctIdxU6B"
      },
      "source": [
        "---\n",
        "---\n",
        "Problem Set 10: Machine Learning II\n",
        "\n",
        "Applied Data Science using Python\n",
        "\n",
        "New York University, Abu Dhabi\n",
        "\n",
        "Out: 21st Nov 2023 || **Due: 28th Nov 2023 at 23:59**\n",
        "\n",
        "---\n",
        "---\n",
        "#Start Here\n",
        "## Learning Goals\n",
        "### General Goals\n",
        "- Learn the fundamental concepts of applied machine learning\n",
        "- Learn the fundamental concepts of supervised learning\n",
        "\n",
        "### Specific Goals\n",
        "- Learn the basics of regression\n",
        "- Learn to apply different models of regression:\n",
        "    - linear regression\n",
        "    - polynomial regression\n",
        "    - kNN regression\n",
        "- Understand bias-variance tradeoff\n",
        "- Learn to apply cross validation\n",
        "- Learn to apply regularization (L1 vs. L2)\n",
        "- Learn to evaluate and compare the performance of your regression models\n",
        "- Learn to apply feature scaling\n",
        "- Feature engineering\n",
        "- Understand transfer learning\n",
        "\n",
        "## Collaboration Policy\n",
        "- You are allowed to talk with / work with other students on homework assignments.\n",
        "- You can share ideas but not code, analyses or results; you must submit your own code and results. All submitted code will be compared against all code submitted this and previous semesters and online using MOSS. We will also critically analyze the similarities in the submitted reports, methodologies, and results, **but we will not police you**. We expect you all to be mature and responsible enough to finish your work with full integrity.\n",
        "- You are expected to comply with the [University Policy on Academic Integrity and Plagiarism](https://www.nyu.edu/about/policies-guidelines-compliance/policies-and-guidelines/academic-integrity-for-students-at-nyu.html). Violations may result in penalties, such as failure in a particular assignment.\n",
        "\n",
        "## Distribution of Class Materials\n",
        "These problem sets and recitations are intellectual property of NYUAD, and we request the students to **not** distribute them or their solutions to other students who have not signed up for this class, and/or intend to sign up in the future. We also request you don't post these problem sets, and recitations online or on any public platforms.\n",
        "\n",
        "## Late Submission Policy\n",
        "You can submit the homework for upto 3 late days. However, we will deduct **20 points** from your homework grade **for each late day you take**. We will not accept the homework after 3 late days.\n",
        "\n",
        "\n",
        "## Disclaimer\n",
        "The number of points do not necessarily signify/correlate to the difficulty level of the tasks.\n",
        "\n",
        "## Submission\n",
        "You will submit all your code as a Python Notebook through [Brightspace](https://brightspace.nyu.edu/) as **P10_YOUR NETID.ipynb**.\n",
        "\n",
        "## Kaggle Username\n",
        "\n",
        "Leaderboard: LosPodiumHermanos  \n",
        "Username: IDontKnowWhatIAmDoing\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPMDlF4mjG6v"
      },
      "source": [
        "# General Instructions\n",
        "This homework is worth 100 points. It has 2 parts. Below each part, we provide a set of concepts required to complete that part. All the parts need to be completed in this Jupyter (Colab) Notebook. Please start this homework early as modeling may take some time.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SWf22cCjQNY"
      },
      "source": [
        "# Part I: Predicting the Prevalence of the CCD Disease (70 points)\n",
        "\n",
        "For a long time now, humans of the **United States of America (USA)** have been suffering from a communicable disease called the CCD, short for the **Climate Change Denialism**, a serious disease that is making humans incapable to reason. True story! <sup>1</sup>\n",
        "\n",
        "The Center of Logical Reasoning has been collecting the data related to the disease since 2010, and has reached out to NYU for help in creating a model for the prediction of the prevalance of **Climate Change Denialism** in different states using a set of features. The dataset is **spatio-temporal** as it has prevalance rates of the disease for ~50 states (spatial), across 7 years (temporal).\n",
        "\n",
        "------------------\n",
        "<sup>1. This is a work of fiction. The story, names, writing, data depicted in this problem set are mostly ficticious. Any similarity to actual persons, living or dead, or to actual papers, is not purely coincidental but definitely inspirational. The \"Climate Change Denialism\" is a fictitious disease that may have been inspired by a same name disorder found amongst certain individuals in the world.</sup>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfGNVsfFlYHV"
      },
      "source": [
        "## A. Training for the US (35 points)\n",
        "\n",
        "Using the dataset `us_train.csv`, train a machine learning based regression model that predicts the prevalence of **Climate Change Denialism** disease for a particular state in the USA. The features are in the columns labeled as `A`, `B`, ..., `AC`. The outcome variable (i.e. the prevalence of CCD disease) is present in the column `outcome`.\n",
        "\n",
        "You may try different models (linear, polynomial, kNN) to see which one performs the best for estimation of the prevalence of the disease. You have data for the years 2010 to 2015 for 50 states in the U.S. Your data will be tested on data from 2016. The features for 2016 are provided in the file `us_test_x.csv`. The outcome/labels for 2016 are not provided.\n",
        "\n",
        "For this part, you are required to train and evaluate your regression models very similar to what we did in the recitation.\n",
        "\n",
        "As a submission for this part, you will fill the `us_predictions.csv` file and submit that along with this Notebook to Brightspace. You will also submit `us_predictions.csv` file to Kaggle (see Part B)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "0DHhFABDkXB6"
      },
      "outputs": [],
      "source": [
        "# Importing libraries you \"may\" need\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "from scipy import stats\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "5lHr1i-Eq2ID"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load the datasets\n",
        "train_data_path = 'us_train.csv'\n",
        "test_data_path = 'us_test_x.csv'\n",
        "train_data = pd.read_csv(train_data_path)\n",
        "test_data = pd.read_csv(test_data_path)\n",
        "\n",
        "# Separate features and target from training data\n",
        "X_train = train_data.drop(['outcome'], axis=1)\n",
        "y_train = train_data['outcome']\n",
        "X_test = test_data.copy()\n",
        "\n",
        "# Preprocessing steps\n",
        "# 1. Impute missing values\n",
        "# 2. One-hot encode the 'states' column\n",
        "# 3. Drop the 'Id' column\n",
        "# 4. Normalize / scale the features\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', SimpleImputer(strategy='median'), [col for col in X_train.columns if col not in ['Id', 'states']]),\n",
        "        ('cat', OneHotEncoder(), ['states'])\n",
        "    ],\n",
        "    remainder='drop'  # drop the columns not specified in transformers (a.k.a. the 'Id' column)\n",
        ")\n",
        "\n",
        "# Creating a pipeline that first preprocesses the data and then applies scaling\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('scaler', StandardScaler())])\n",
        "\n",
        "# Fit and transform the training data, transform the testing data\n",
        "X_train_processed = pipeline.fit_transform(X_train)\n",
        "X_test_processed = pipeline.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Linear Regression MAE: 0.6769149326536387\n",
            "Polynomial Regression MAE: 0.7155699353633228\n",
            "KNN Regression MAE: 0.6071111111111112\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Linear Regression\n",
        "linear_model = LinearRegression()\n",
        "linear_scores = cross_val_score(linear_model, X_train_processed, y_train, cv=5, scoring='neg_mean_absolute_error')\n",
        "linear_mae = -np.mean(linear_scores)\n",
        "\n",
        "# Polynomial Regression (degree 2)\n",
        "poly_model = make_pipeline(PolynomialFeatures(degree=2), LinearRegression())\n",
        "poly_scores = cross_val_score(poly_model, X_train_processed, y_train, cv=5, scoring='neg_mean_absolute_error')\n",
        "poly_mae = -np.mean(poly_scores)\n",
        "\n",
        "# KNN Regression\n",
        "knn_model = KNeighborsRegressor(n_neighbors=3)\n",
        "knn_scores = cross_val_score(knn_model, X_train_processed, y_train, cv=5, scoring='neg_mean_absolute_error')\n",
        "knn_mae = -np.mean(knn_scores)\n",
        "\n",
        "print(f\"Linear Regression MAE: {linear_mae}\")\n",
        "print(f\"Polynomial Regression MAE: {poly_mae}\")\n",
        "print(f\"KNN Regression MAE: {knn_mae}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Lasso MAE: 0.46289202260645174 with alpha: 0.004832930238571752\n",
            "Best Ridge MAE: 0.47010888438516807 with alpha: 4.281332398719396\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Define the alpha grid\n",
        "alpha_grid = {'alpha': np.logspace(-4, 4, 20)}\n",
        "\n",
        "# Lasso Regression with GridSearchCV\n",
        "lasso = Lasso()\n",
        "lasso_cv = GridSearchCV(lasso, alpha_grid, scoring='neg_mean_absolute_error', cv=10)\n",
        "lasso_cv.fit(X_train_processed, y_train)\n",
        "best_lasso_model = lasso_cv.best_estimator_\n",
        "print(\"Best Lasso MAE:\", -lasso_cv.best_score_, \"with alpha:\", lasso_cv.best_params_['alpha'])\n",
        "\n",
        "# Ridge Regression with GridSearchCV\n",
        "ridge = Ridge()\n",
        "ridge_cv = GridSearchCV(ridge, alpha_grid, scoring='neg_mean_absolute_error', cv=10)\n",
        "ridge_cv.fit(X_train_processed, y_train)\n",
        "best_ridge_model = ridge_cv.best_estimator_\n",
        "print(\"Best Ridge MAE:\", -ridge_cv.best_score_, \"with alpha:\", ridge_cv.best_params_['alpha'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Fit the best model to the entire training data\n",
        "best_model = best_lasso_model\n",
        "best_model.fit(X_train_processed, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions_2016 = best_model.predict(X_test_processed)\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    \"Id\": test_data['Id'],\n",
        "    \"Predicted\": predictions_2016\n",
        "})\n",
        "submission.to_csv('us_predictions.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoSZ0d_jaBYH"
      },
      "source": [
        "### Rubric\n",
        "\n",
        "- +20 points for logical and reasonable steps to training and testing the models using the techniques taught in the course\n",
        "- +15 points showing code and evaluation of **at least two regression models** at least one of which makes the same predictions as submitted on Kaggle and in the document `us_predictions.csv`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQkC-_qeYvnL"
      },
      "source": [
        "## B. Kaggle Submission (35 points)\n",
        "\n",
        "Create an account on Kaggle, and submit your predictions as `us_predictions.csv` with the two columns `Id` and `Predicted` to Kaggle.\n",
        "\n",
        "You will be evaluated on the `Mean Absolute Error` as a scoring metric.\n",
        "\n",
        "There are seven benchmarks/baselines that we have provided you on Kaggle. These are as follows:\n",
        "\n",
        "- `Trivial Baseline`\n",
        "- `Baseline A (1 and 2)`\n",
        "- `Baseline B (1 and 2)`\n",
        "- `Baseline C (1 and 2)`\n",
        "\n",
        "To be able to get full points on this task, you would need to pass the `Trivial Baseline`, either of `A1` or `A2`, either of `B1` or `B2`, **and** either of `C1` or `C2` baseline.\n",
        "\n",
        "Note that the score you see on Kaggle Leaderboard for your submission is only based on 50% of the test dataset (i.e. 25 data points) -- we have hidden the other 50% of the dataset, and your score on those will only be revealed once the competition ends. In general, if you pass the baseline on the publicly available data, your model should pass the baselines on the hidden data as well. But we have kept it hidden so that you don't overfit your model on the test set.\n",
        "\n",
        "The Kaggle data points for the test set are from 2016 the features for which are provided in `us_test_x.csv`.\n",
        "\n",
        "You have a maximum for 15 submissions per day on Kaggle. Before submitting the notebook, enter your Kaggle username in the **Kaggle Username** section above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NH5VV_UXWFZe"
      },
      "source": [
        "### Rubric\n",
        "\n",
        "- +10 points for achieving/crossing Baseline A1 or Baseline A2 across both public (7 points) and hidden data points (3 points).\n",
        "- +5 points for achieving/crossing Trivial Baseline across both public (3 points) and hidden data points (2 points).\n",
        "- +10 points for achieving/crossing Baseline B1 or Baseline B2 across both public (7 points) and hidden data points (3 points).\n",
        "- +10 points for achieving/crossing Baseline C1 or Baseline C2 across both public (7 points) and hidden data points (3 points).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goGyqP7dnRhU"
      },
      "source": [
        "## *Concepts required to complete this task*\n",
        "\n",
        "*   Basics of Machine Learning\n",
        "*   Basics of Regression\n",
        "*   Feature Engineering\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuRYqcxmn4vS"
      },
      "source": [
        "# Part II: Transfer Learning (30 points)\n",
        "\n",
        "Many machine learning methods work well only under a common assumption: the training and test data are drawn from the same feature space and/or the same distribution. When the distribution changes, most statistical models need to be rebuilt from scratch using newly collected training data. In many real world applications, it is expensive or impossible to recollect the needed training data and rebuild the models. It would be nice to reduce the need and effort to recollect the training data. In such cases, **knowledge transfer** or **transfer learning** between task domains would be desirable.\n",
        "\n",
        "**Transfer learning** is a machine learning method where a model developed for a task is reused for a model on a second task. For example, in the paper on *Revealing Inherent Gender Biases in Using Word Embeddings for Sentiment Analysis* in PS7, the (imaginary) authors used word embeddings for sentiment analysis. That was a transfer learning approach where word embeddings were created from a machine learning model that was trained for the purpose of [predicting words](https://machinelearningmastery.com/develop-word-based-neural-language-models-python-keras/#:~:text=Language%20modeling%20involves%20predicting%20the,machine%20translation%20and%20speech%20recognition.), but the model was later **reused** to extract word embeddings to be used for the sentiment analysis task. Another example would be a **spam filtering model** that has been trained on emails of one user (the source distribution) and is applied to a new user who receives significantly different emails (the target distribution). This process of applying the model to a different target distribution is sometimes also known as **domain adaptation**. <Sup>2</Sup>\n",
        "\n",
        "---------\n",
        "<sup> 2. Some people distinguish between **transfer learning** and **domain adaptation**, some don't. These are not very precisely defined terms in the literature.</sup>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzpsVzu8ovqK"
      },
      "source": [
        "## A. Cross-Country Generalizability of the Model (15 points)\n",
        "\n",
        "Using a model trained on all the data from the United States, estimate the prevalence of Climate Change Denialism disease for the 8 provinces of the **Dominion of Canada** for the years 2011 to 2014. You may have to modify and retrain your model according to the data and features available to you for Canada.\n",
        "\n",
        "The dataset (i.e. features) for Canada is available as `ca_test_x.csv`. You will submit your final predictions as `ca_predictions.csv` the template for which is provided to you in the handout. As you will notice, the features for Canada are a subset of the features for the USA, therefore, you'll have to train your US based model accordingly.\n",
        "\n",
        "As a submission for this part, you will fill the `ca_predictions.csv` file and submit that along with this Notebook to Brightspace. You will also submit `ca_predictions.csv` file to Kaggle (see Part B)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "# Load the U.S. training data again\n",
        "us_train_path = 'us_train.csv'\n",
        "us_train_data = pd.read_csv(us_train_path)\n",
        "\n",
        "# Select the features that are also present in the Canadian dataset\n",
        "selected_features = ['B', 'F', 'H', 'I', 'K', 'L', 'M', 'O', 'T', 'W', 'X', 'Y', 'AA', 'AC']\n",
        "X_train = us_train_data[selected_features]\n",
        "y_train = us_train_data['outcome']\n",
        "\n",
        "# Preprocessing the data\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', SimpleImputer(strategy='mean'), selected_features)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Creating a pipeline that first preprocesses the data and then applies scaling\n",
        "pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                           ('scaler', RobustScaler())])\n",
        "\n",
        "# Fit and transform the training data\n",
        "X_train_processed = pipeline.fit_transform(X_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the alpha grid\n",
        "alpha_grid = {'alpha': np.logspace(-10, 10, 100)}\n",
        "\n",
        "# Ridge Regression with GridSearchCV\n",
        "ridge = Ridge()\n",
        "ridge_cv = GridSearchCV(ridge, alpha_grid, scoring='neg_mean_absolute_error', cv=10)\n",
        "ridge_cv.fit(X_train_processed, y_train)\n",
        "best_ridge_model = ridge_cv.best_estimator_\n",
        "\n",
        "# Lasso Regression with GridSearchCV\n",
        "lasso = Lasso()\n",
        "lasso_cv = GridSearchCV(lasso, alpha_grid, scoring='neg_mean_absolute_error', cv=10)\n",
        "lasso_cv.fit(X_train_processed, y_train)\n",
        "best_lasso_model = lasso_cv.best_estimator_\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "# knn Regression with GridSearchCV\n",
        "param_grid = {'n_neighbors': range(1, 101, 2)}\n",
        "knn = KNeighborsRegressor()\n",
        "knn_cv = GridSearchCV(knn, param_grid, scoring='neg_mean_absolute_error', cv=10)\n",
        "knn_cv.fit(X_train_processed, y_train)\n",
        "best_knn_model = knn_cv.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Linear Regression\n",
        "linear_model = LinearRegression()\n",
        "linear_scores = cross_val_score(linear_model, X_train_processed, y_train, cv=10, scoring='neg_mean_absolute_error')\n",
        "linear_mae = -np.mean(linear_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Polynomial Regression (degree 2)\n",
        "poly_model = make_pipeline(PolynomialFeatures(degree=2), LinearRegression())\n",
        "poly_scores = cross_val_score(poly_model, X_train_processed, y_train, cv=10, scoring='neg_mean_absolute_error')\n",
        "poly_mae = -np.mean(poly_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best Ridge MAE: 0.8565632065493402 with alpha: 5.0941380148163855\n",
            "Best Lasso MAE: 0.853451830837769 with alpha: 0.012045035402587835\n",
            "Best KNN MAE: 0.7463333333333333 with n_neighbors: 3\n",
            "Linear Regression MAE: 0.8586570826798494\n",
            "Polynomial Regression MAE: 1.0990142984376041\n"
          ]
        }
      ],
      "source": [
        "# Print the best model and its MAE score\n",
        "print(\"Best Ridge MAE:\", -ridge_cv.best_score_, \"with alpha:\", ridge_cv.best_params_['alpha'])\n",
        "print(\"Best Lasso MAE:\", -lasso_cv.best_score_, \"with alpha:\", lasso_cv.best_params_['alpha'])\n",
        "print(\"Best KNN MAE:\", -knn_cv.best_score_, \"with n_neighbors:\", knn_cv.best_params_['n_neighbors'])\n",
        "print(\"Linear Regression MAE:\", linear_mae)\n",
        "print(\"Polynomial Regression MAE:\", poly_mae)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the Canadian test data\n",
        "ca_test_path = 'ca_test_x.csv'\n",
        "ca_test_data = pd.read_csv(ca_test_path)\n",
        "X_test_ca = ca_test_data[selected_features]\n",
        "\n",
        "# Transform the testing data using the same pipeline\n",
        "X_test_ca_processed = pipeline.transform(X_test_ca)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make predictions on the Canadian test set\n",
        "ca_predictions = best_lasso_model.predict(X_test_ca_processed)\n",
        "\n",
        "# Prepare the submission file\n",
        "submission_ca = pd.DataFrame({\n",
        "    \"Id\": ca_test_data['Id'],\n",
        "    \"Predicted\": ca_predictions\n",
        "})\n",
        "submission_ca.to_csv('ca_predictions.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gk6-XiEMFItX"
      },
      "source": [
        "### Rubric\n",
        "\n",
        "- +5 points for logical and reasonable steps to training and testing the models using the techniques taught in the course\n",
        "- +10 points showing code and evaluation of **at least two regression models** at least one of which makes the same predictions as submitted on Kaggle and in the document `ca_predictions.csv`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhewfxmLpQYj"
      },
      "source": [
        "## B. Kaggle Submission (15 points)\n",
        "\n",
        "You will submit your predictions as `ca_predictions.csv` with the two columns `Id` and `Predicted` to Kaggle.\n",
        "\n",
        "You will be evaluated on the `Mean Absolute Error` scoring metric.\n",
        "\n",
        "There is one benchmark/baseline that we have provided you on Kaggle that you will have to meet/beat to receive all the points.\n",
        "\n",
        "Note that the score you see on Kaggle Leaderboard for your submission is only based on 75% of the dataset (i.e. 24 data points) -- we have hidden 25% of the dataset (8 data points), and your score on those will only be revealed once the competition ends.\n",
        "\n",
        "You have a maximum for 15 submissions per day on Kaggle. Before submitting the notebook, enter your Kaggle username in the **Kaggle Username** section above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRVWGA6-EmVg"
      },
      "source": [
        "### Rubric\n",
        "\n",
        "- +15 points for achieving/crossing the baseline provided across both public (10 points) and hidden data points (5 points)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N08hHBwwoHHT"
      },
      "source": [
        "## *Concepts required to complete this task*\n",
        "\n",
        "*   Basics of Machine Learning\n",
        "*   Basics of Regression\n",
        "*   Feature Engineering\n",
        "*   Concept of Transfer Learning"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "PUxdctIdxU6B"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
