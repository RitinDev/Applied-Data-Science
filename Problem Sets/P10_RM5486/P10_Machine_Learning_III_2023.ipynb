{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUxdctIdxU6B"
      },
      "source": [
        "---\n",
        "---\n",
        "Problem Set 10: Machine Learning III\n",
        "\n",
        "Applied Data Science using Python\n",
        "\n",
        "New York University, Abu Dhabi\n",
        "\n",
        "Out: 28 Nov 2023 || **Due: 07 Dec 2023 at 23:59**\n",
        "\n",
        "---\n",
        "---\n",
        "#Start Here\n",
        "## Learning Goals\n",
        "### General Goals\n",
        "- Learn the fundamental concepts of applied machine learning\n",
        "- Learn the basic and advanced machine learning models\n",
        "\n",
        "\n",
        "### Specific Goals\n",
        "- Learn to apply different models for classification and regression\n",
        "- Learn about different modalities of data\n",
        "- Trade-offs between performance and computation\n",
        "\n",
        "## Collaboration Policy\n",
        "- You are allowed to talk with / work with other students on homework assignments.\n",
        "- You can share ideas but not code, analyses or results; you must submit your own code and results. All submitted code will be compared against all code submitted this and previous semesters and online using MOSS. We will also critically analyze the similarities in the submitted reports, methodologies, and results, **but we will not police you**. We expect you all to be mature and responsible enough to finish your work with full integrity.\n",
        "- You are expected to comply with the [University Policy on Academic Integrity and Plagiarism](https://www.nyu.edu/about/policies-guidelines-compliance/policies-and-guidelines/academic-integrity-for-students-at-nyu.html). Violations may result in penalties, such as failure in a particular assignment.\n",
        "\n",
        "## Late Submission Policy\n",
        "You can submit the homework for upto 3 late days. However, we will deduct **20 points** from your homework grade **for each late day you take**. We will not accept the homework after 3 late days.\n",
        "\n",
        "## Distribution of Class Materials\n",
        "These problem sets and recitations are intellectual property of NYUAD, and we request the students to **not** distribute them or their solutions to other students who have not signed up for this class, and/or intend to sign up in the future. We also request you don't post these problem sets, and recitations online or on any public platforms.\n",
        "\n",
        "## Disclaimer\n",
        "The number of points do not necessarily signify/correlate to the difficulty level of the tasks.\n",
        "\n",
        "## Submission\n",
        "You will submit all your code as a Python Notebook through [Brightspace](https://brightspace.nyu.edu/) as **P11_YOUR NETID.ipynb**.\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPMDlF4mjG6v"
      },
      "source": [
        "# General Instructions\n",
        "This homework is worth 100 points. It has 3 parts. Below each part, we provide a set of concepts required to complete that part. All the parts need to be completed in this Jupyter (Colab) Notebook. **Start this homework early as the dataset is huge, and modeling will take a lot more time than your previous homeworks and recitations.**\n",
        "\n",
        "*For this homework, we will not explicitly tell you which models to use. Now that you are aware of the different machine learning models, all the models you have learnt are fair game.*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_sLJNn6u0J6x"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9Z3_zHDOJhV"
      },
      "source": [
        "## Modalities\n",
        "\n",
        "There are typically (though arguably) 6 different **modalities** or modes of data that a data scientist encounters in their work: (i) numbers; (ii) text; (iii) images; (iv) audio/speech; (v) video, and (vi) graphs/networks.\n",
        "\n",
        "There are separate fields and courses pertaining to each of these modalities offered in many of the academic institutions. For example, if you want to learn about text, you would take a *Natural Language Processing (NLP)* or a *Text Processing* course. For in-depth understanding of images and video, you would take a *Multimedia Analysis* or a *Computer Vision (CV)* course. To learn about audio or speech, you would take a *Speech Processing* or *Audio Processing* course. To learn about graphs and networks, you would take a *Network Science* or a *Graph Theory* course. These courses cover in-depth understanding of how to *process* and *represent* data of a given modality, and also teach the basic challenges within each field. That said, as of 2021, most of the state-of-the-art methods to deal with all of these modalities have somehow coverged to using *neural networks* in some form, and so to learn the state-of-the-art methods in neural networks, you would take a *Deep learning* course. Still, learning about the basics of how to *represent* data from different modalities is key to being successful in that particular field.\n",
        "\n",
        "In most of your assignments so far, you have dealt with the first modality i.e. numbers. This is by design, as all the other modalities can typically be converted to (scalars or vectors or some form of) numbers, and so dealing with other modalities mostly requires you to *transform* your data to numbers: *Textual data* can be converted to frequency values or other vector representations as you have briefly seen in P7 and R12; *images* typically get converted to pixel values or other vector representations; *videos* are basically images in time; *speech/audio* typically get converted to spectrograms which are basically similar to images; finally, *networks* can be represented as lists, matrices or vector representations. But, in the end, all data is just numbers. Arguably, most data can just be converted to vectors or as you now know *embeddings*. This has led to papers such as [*Word2Vec*](https://arxiv.org/abs/1301.3781) for text, [*Wave2Vec*](https://ai.facebook.com/blog/wav2vec-state-of-the-art-speech-recognition-through-self-supervision/) for speech, [*node2vec*](https://dl.acm.org/doi/abs/10.1145/2939672.2939754) and [*graph2vec*](https://arxiv.org/abs/1707.05005) for graphs and networks, and so on.\n",
        "\n",
        "To reiterate, an *embedding* is a relatively *low-dimensional* space into which you can translate high-dimensional vectors/data. Some images are big, some images are small, some images are black and white, some are RGB. Similarly, some voice recordings are long, some are short. Embeddings are a way to (i) represent high dimensional data into a compact representation to easily deal with the data in downstream tasks, and (ii) one that is standardized across different types of data. As a result, they make relationships between different instances easier and more *meaningful* like you saw in the case of *Word embeddings* in the *visualization* assignment.\n",
        "\n",
        "In this assignment, you will use *embeddings* not for words, but instead for *speech* (or *speakers*) for the task of *speaker recognition/identification*, *speaker gender recognition*, and *speaker age estimation*.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuRYqcxmn4vS"
      },
      "source": [
        "## Motivation: Solving Voice Crimes Using d-vectors\n",
        "\n",
        "The [United States Coast Guard (USCG)](https://en.wikipedia.org/wiki/United_States_Coast_Guard) handles about 16,000 *Mayday* calls for help every year. Every distress call the Coast Guard receives compels the federal agency to launch an expensive search-and-rescue effort involving at a minimum a small rescue boat, a C-130 fixed-wing aircraft or rescue helicopter, and the several Coast Guardsmen to operate them. The cost of each outing can run from \\$10,000 to \\$250,000. Small boats typically cost \\$4,500 per hour to operate, whereas the helicopters can cost about \\$16,000.\n",
        "\n",
        "Unfortunately,  **about 1 percent of these distress calls are fake**. The men and women of the Coast Guard put themselves at risk every time the surface and air assets respond to a call for assistance. **Hoax callers** place Coast Guardsmen at unnecessary risk. Furthermore, hoax calls interfere with legitimate search and rescue cases, diverting assets from being available to help actual mariners in distress.\n",
        "\n",
        "The penalty for transmitting a hoax distress call to the Coast Guard is up to six years in prison, a \\$250,000 fine, a \\$5,000 civil fine, and reimbursement to the Coast Guard for the cost of performing the search. Nevertheless, recently, an anonymous caller cost the U.S. Coast Guard roughly \\$500,000 by sending first responders on unnecessary rescue missions 28 times through hoax calls. The hoax caller made 28 calls, everytime speaking in a different voice to fool USCG. *True story*. <sup>1</sup>\n",
        "\n",
        "Unfortunately, the USCG does not have a system to be able to identify the voice of the person making the call. If they had such a system, every time a distress call came, they could have matched it to the voices of the callers from the past to make sure it was a legit call. If a caller had been red-flagged in the past, such a system would have been able to identify if the same person made the call again just by using a voice-matching system.\n",
        "\n",
        "Your voice is like a fingerprint, and a voice-matching system is typically robust enough to not be fooled even if you try to change your voice.\n",
        "\n",
        "The USCG has thus reached out to NYUAD's data scientists for help in creating a system through which they can recognize speakers through their voices. Because most fake callers do not speak in their own voice, USCG is not even able to make out other states of the caller such as their gender. Therefore USCG would want to go one step ahead and also create two other machine learning models that are able to detect the **gender**, and the **age** of the speaker.\n",
        "\n",
        "In this homework, you will use *speaker embeddings* which we will call *d-vectors* (\"d\" representing the deep neural networks) as features to accomplish three tasks by training three machine learning models:\n",
        "\n",
        "-*Voice2SpeakerID: model for predicting the ID of the speaker from voice*\n",
        "\n",
        "-*Voice2Gender: model for predicting gender of the speaker from voice*\n",
        "\n",
        "-*Voice2Age: model for estimating the age of the speaker from voice*\n",
        "\n",
        "These three models will be created using the machine learning techniques you have learnt in the class.\n",
        "\n",
        "------------------\n",
        "<sup>1. Well, this is actually a [true story](https://www.dhs.gov/science-and-technology/news/2017/09/26/snapshot-voice-forensics-can-help-coast-guard-catch-hoax) :) </sup>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2jWsbV8mB4E"
      },
      "source": [
        "## Dataset\n",
        "\n",
        "The dataset you are given is a preprocessed version of voice recordings collected by the United States Coast Guard, and is attached with the handout in three parts:\n",
        "\n",
        "- 1. **voice_forensics_train.csv**: The dataset contains the training dataset that you will use across all three tasks. There are **7078** speakers in the dataset with each speaker having **4** recordings and hence 4 rows. As a result, there are **28312** rows. It has 132 columns. These columns are:\n",
        "    - *Id:* This is the unique identifier for each row.\n",
        "    - *speaker_id:* This is the unique identifier for each **speaker**.\n",
        "    - *gender*: This is the self-identified gender of the speaker as \"male\" for male, or \"female\" for female.\n",
        "    - *age*: This is the age of the speaker.\n",
        "    - *d1,d2,...d128*: These values represent the 128-dimensional d-vector for the current speaker's current recording. Because each speaker has 4 recordings, therefore, each speaker has 4 different d-vectors.<sup>2</sup>\n",
        "\n",
        "- 2. **voice2speakerid_test_x.csv**: This is the test dataset for the **Voice2SpeakerID** model. The labels are hidden for this dataset, as you will use your model to predict the labels for this dataset, and submit to Kaggle. This file contains 14156 rows, and 129 columns. These columns are:\n",
        "    - *Id:* This is the unique identifier for each row. (This is the identifier you will use for submission to Kaggle.)\n",
        "    - *d1,d2,...d128*. These values represent the 128-dimensional d-vector for the current speaker's current recording. You have to use these features to **match** the *speaker_id* from your training set.\n",
        "\n",
        "- 3. **voice2genderage_test_x.csv**: This is the test dataset for the **Voice2Gender** and **Voice2Age** model. The labels are hidden for this dataset, as you will use your model to predict the labels for this dataset, and submit to Kaggle. This file contains 8802 rows, and 129 columns. These columns are:\n",
        "    - *Id:* This is the unique identifier for each row. (This is the identifier you will use for submission to Kaggle.)\n",
        "    - *d1,d2,...d128*. These values represent the 128-dimensional d-vector for the current speaker's current recording. You have to use these features to predict the *gender* and *age* of the speaker.\n",
        "\n",
        "The 128-dimensional d-vectors are extracted from a complex deep learning based speaker identification model from this [paper](http://mlsp.cs.cmu.edu/people/rsingh/docs/pairwiseloss.pdf). In simple terms, all audio recordings are converted to [spectrograms](https://en.wikipedia.org/wiki/Spectrogram), which are then used to train a neural network model. Once the neural network is trained, a *d-vector* or *embedding* is extracted by passing each audio recording one-by-one through the trained neural network as shown in the diagram below.\n",
        "\n",
        "![dvector](https://drive.google.com/uc?id=1abh5I0U3wI1LR3myScD4dpIdvjYMeqjP)\n",
        "\n",
        "**If you do not understand this, *THAT'S OK*. For the purposes of this assignment, think of each d-vector as a feature representation of an audio/speech recording of a person which you will use to create your models. Similar to how words can be represented using word-embeddings or a BoW embedding, audio/speech recordings can be represented as d-vectors or audio/speech embeddings**.\n",
        "\n",
        "You will use the same dataset for training across all three tasks. Your independent variable or *features* will remain the same for **all** the tasks (unless you augment some new features). What will change then? (i) the target/dependent variable; (ii) the model and the model parameters; and of course (iii) the evaluation metrics and performance based on whether the task is a classification task or a regression task.\n",
        "\n",
        "-------\n",
        "\n",
        "<sup>2. We saw in PS7 that an interesting property of **embeddings** is that they form meaningful relationships. We saw this concretely in the case of word embeddings where in a scatter plot of words, words which were *similar* formed clusters. This is a property that you will also find within *d-vectors*. More concretely, in this dataset, we have given you 4 d-vectors for each speaker. What you will notice is that if you take the **euclidean distance** of two d-vectors from the same speaker, and the **euclidean distance** of any of those two d-vectors to a d-vector from another speaker, the euclidean distance between d-vectors from same speaker will be much smaller i.e. **d-vectors from the same speaker will be closer to each other**. If you are curious, you can check this for yourself by selecting a few random speakers and d-vectors, and using scikit-learn's **[euclidean distance metric](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.euclidean_distances.html)** to compute distances. This should also give you a clue on how to use these d-vectors to create a model for **Voice2SpeakerID** task. :)</sup>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6s_IBHhEA8F"
      },
      "source": [
        "## Evaluation Metrics\n",
        "Once you have trained your model, it is very important to evaluate your model using the *right* metric. For example, accuracy, while widely used, is generally *not* a good metric especially when the data is not balanced across the different classes. *Precision*, *Recall*, *F1*, and *Area Under the Curve (AUC)* are almost always considered better choices. For regression tasks, *Mean Absolute Error (MAE)*, *Root Mean Squared Error (RMSE)*, and *R-Squared (R2)* are some of the popular choices. Make yourselves familiar with these different metrics by googling about that. Here are some articles that will be useful for understanding **[ROC AUC Score](https://machinelearningmastery.com/roc-curves-and-precision-recall-curves-for-classification-in-python/)**, and **[F1 score](https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9)**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOC76SDQmvWW"
      },
      "source": [
        "## Hints:\n",
        "\n",
        "- We highly recommend that you do the parts in the order they are presented in the problem set.\n",
        "\n",
        "- The problem sets that you have worked on so far were not easy but they were all the same in one aspect: *they required less computation, and a lot more thinking*. This problem set is different from all others because it revolves around a large dataset and requires more computation and arguably less thinking. If you ever want to pursue a career in machine learning, you will deal with datasets that are as large, if not more, as this, and will deal with the same problems. We could have instead given you a small dataset, but a big goal of this homework is for you to be able to deal with large real-world datasets.\n",
        "\n",
        "- Because it’s a large dataset, it is likely that your models will take more time to train (and test). Therefore, running time can range from a minute to even hours if you are using grid search over many parameters. The strategy for this homework, therefore, is to start with simpler models without grid search and parameter tuning — models that will train and predict quicker, and then gradually add grid search and other parameters if needed. If you cannot figure out via intuition which models are simple and will supposedly run quicker, you can figure this out empirically by trying them out on a small subset of your training set (i.e. via sampling). If your model is taking more than 10 minutes, then it’s not a simple model, try something simpler first. If you try simpler models, and are not able to pass the baselines/benchmarks, only then move to complex models, and/or more parameters.\n",
        "\n",
        "- If you use grid search, and it takes a lot of time, you should try smaller values for your number of folds.\n",
        "\n",
        "- Choose your loss and scoring parameters wisely, based on the metric you want to optimize. For example, if the metric is *root mean squared error*, the loss you would like minimized is *L2*. Think why.\n",
        "\n",
        "- If any of your model uses regularization, limit the range of parameters. A rule of thumb is to try values in the *powers of 10* first (eg. `0.001, 0.01, 0.1, 1, 10, 100`), and then gradually move to a finer range if needed.\n",
        "\n",
        "- Part 3 is **not** a classification task. It is a regression task, as such you would try models that employ regression. Most of the classification models you have learnt in class have their corresponding regression modules on scikit-learn. For example for an SVM, you have [SVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) (which is a classifier), and you also have [SVR](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html) (which is a regressor).\n",
        "\n",
        "- If you want to use SVM with a linear kernel, use [LinearSVC](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html) and [LinearSVR](https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVR.html) modules instead of SVC and SVR modules, as the former will run faster.\n",
        "\n",
        "- Normalizing or Standardizing the data is not needed for this assignment. This is because the extracted *d-vectors* were already normalized by the neural network.\n",
        "\n",
        "- For each task, we ask you to submit at least 2 models. This is so that you try different models. If you are lucky and achieve your goal or target performance by simply trying a single model, we do not expect you to spend a lot of time optimizing the second model as long as it performs reasonably. It’s not required for your second model to pass the baselines or benchmarks. We just want to see that you tried a second model with reasonable parameters.\n",
        "\n",
        "- For the last part on Voice2Age, passing Baseline C may require more than just modeling i.e. creatively thinking about the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SWf22cCjQNY"
      },
      "source": [
        "# Part I: Voice2SpeakerID (35 points)\n",
        "\n",
        "Create a model that predicts the *id* of the speaker based on the *d-vector* of their voice as shown in the figure below:\n",
        "\n",
        "![voice2speakerid](https://drive.google.com/uc?id=12nyrSxkbp-wMznX6hYWN3W70UQvSK4a8)\n",
        "\n",
        "This is a **matching** task i.e. we will **not** test your model on speakers that are not represented in the provided training set.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfGNVsfFlYHV"
      },
      "source": [
        "## Prompt\n",
        "\n",
        "More concretely, you will use the d-vectors in `voice_forensics_train.csv` to fit at least two models for the prediction of speaker id from speaker embedding. You will then predict the `speaker_id` of the d-vectors in `voice2speakerid_test_x.csv` and submit the predictions to Kaggle.\n",
        "\n",
        "We have provided you with a sample file as `voice2speakerid_solution_sample.csv`. Use the format of that file to submit your predictions.\n",
        "\n",
        "We have provided three baselines on Kaggle based on the `accuracy` metric which you will need to beat to score full points on this task.\n",
        "\n",
        "For this part, you will submit your code as part of the notebook, and will also submit the `voice2speakerid_solution.csv` file with your predictions to Brightspace as well as to Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "8prkIpcuGjBg"
      },
      "outputs": [],
      "source": [
        "# Load required files\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import warnings\n",
        "# warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load the datasets required for part I\n",
        "train_data = pd.read_csv('voice_forensics_train.csv')\n",
        "test_data = pd.read_csv('voice2speakerid/voice2speakerid_test_x.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>speaker_id</th>\n",
              "      <th>gender</th>\n",
              "      <th>age</th>\n",
              "      <th>d1</th>\n",
              "      <th>d2</th>\n",
              "      <th>d3</th>\n",
              "      <th>d4</th>\n",
              "      <th>d5</th>\n",
              "      <th>d6</th>\n",
              "      <th>...</th>\n",
              "      <th>d119</th>\n",
              "      <th>d120</th>\n",
              "      <th>d121</th>\n",
              "      <th>d122</th>\n",
              "      <th>d123</th>\n",
              "      <th>d124</th>\n",
              "      <th>d125</th>\n",
              "      <th>d126</th>\n",
              "      <th>d127</th>\n",
              "      <th>d128</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>35540</td>\n",
              "      <td>female</td>\n",
              "      <td>45.0</td>\n",
              "      <td>-0.192353</td>\n",
              "      <td>-0.113325</td>\n",
              "      <td>0.076270</td>\n",
              "      <td>-0.025666</td>\n",
              "      <td>0.065720</td>\n",
              "      <td>-0.138643</td>\n",
              "      <td>...</td>\n",
              "      <td>0.004161</td>\n",
              "      <td>0.081468</td>\n",
              "      <td>-0.049854</td>\n",
              "      <td>-0.086956</td>\n",
              "      <td>-0.229366</td>\n",
              "      <td>0.081781</td>\n",
              "      <td>-0.102319</td>\n",
              "      <td>-0.015848</td>\n",
              "      <td>-0.165077</td>\n",
              "      <td>0.072695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>35540</td>\n",
              "      <td>female</td>\n",
              "      <td>45.0</td>\n",
              "      <td>0.012671</td>\n",
              "      <td>-0.020054</td>\n",
              "      <td>-0.080550</td>\n",
              "      <td>-0.066981</td>\n",
              "      <td>-0.023068</td>\n",
              "      <td>0.021807</td>\n",
              "      <td>...</td>\n",
              "      <td>0.070559</td>\n",
              "      <td>0.124623</td>\n",
              "      <td>0.042512</td>\n",
              "      <td>-0.147252</td>\n",
              "      <td>0.068138</td>\n",
              "      <td>0.148022</td>\n",
              "      <td>-0.073004</td>\n",
              "      <td>-0.174536</td>\n",
              "      <td>-0.090798</td>\n",
              "      <td>-0.089854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>35540</td>\n",
              "      <td>female</td>\n",
              "      <td>45.0</td>\n",
              "      <td>0.211005</td>\n",
              "      <td>-0.091166</td>\n",
              "      <td>-0.204517</td>\n",
              "      <td>-0.014342</td>\n",
              "      <td>0.156766</td>\n",
              "      <td>-0.062494</td>\n",
              "      <td>...</td>\n",
              "      <td>0.059373</td>\n",
              "      <td>-0.051881</td>\n",
              "      <td>-0.039299</td>\n",
              "      <td>-0.171386</td>\n",
              "      <td>0.066677</td>\n",
              "      <td>0.129493</td>\n",
              "      <td>-0.169326</td>\n",
              "      <td>-0.052836</td>\n",
              "      <td>-0.100826</td>\n",
              "      <td>-0.097579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>35540</td>\n",
              "      <td>female</td>\n",
              "      <td>45.0</td>\n",
              "      <td>-0.093959</td>\n",
              "      <td>-0.181139</td>\n",
              "      <td>0.072483</td>\n",
              "      <td>0.055215</td>\n",
              "      <td>0.046015</td>\n",
              "      <td>-0.152144</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.008471</td>\n",
              "      <td>0.026831</td>\n",
              "      <td>-0.063509</td>\n",
              "      <td>-0.168682</td>\n",
              "      <td>-0.137628</td>\n",
              "      <td>0.096271</td>\n",
              "      <td>-0.109646</td>\n",
              "      <td>0.036716</td>\n",
              "      <td>-0.198027</td>\n",
              "      <td>0.030743</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>73465</td>\n",
              "      <td>female</td>\n",
              "      <td>27.0</td>\n",
              "      <td>-0.123451</td>\n",
              "      <td>-0.140431</td>\n",
              "      <td>0.049797</td>\n",
              "      <td>-0.083786</td>\n",
              "      <td>-0.067806</td>\n",
              "      <td>0.017086</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.098829</td>\n",
              "      <td>0.037679</td>\n",
              "      <td>0.105494</td>\n",
              "      <td>0.014183</td>\n",
              "      <td>-0.011838</td>\n",
              "      <td>0.053571</td>\n",
              "      <td>0.031440</td>\n",
              "      <td>-0.030806</td>\n",
              "      <td>-0.126419</td>\n",
              "      <td>-0.033699</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 132 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  speaker_id  gender   age        d1        d2        d3        d4  \\\n",
              "0   0       35540  female  45.0 -0.192353 -0.113325  0.076270 -0.025666   \n",
              "1   1       35540  female  45.0  0.012671 -0.020054 -0.080550 -0.066981   \n",
              "2   2       35540  female  45.0  0.211005 -0.091166 -0.204517 -0.014342   \n",
              "3   3       35540  female  45.0 -0.093959 -0.181139  0.072483  0.055215   \n",
              "4   4       73465  female  27.0 -0.123451 -0.140431  0.049797 -0.083786   \n",
              "\n",
              "         d5        d6  ...      d119      d120      d121      d122      d123  \\\n",
              "0  0.065720 -0.138643  ...  0.004161  0.081468 -0.049854 -0.086956 -0.229366   \n",
              "1 -0.023068  0.021807  ...  0.070559  0.124623  0.042512 -0.147252  0.068138   \n",
              "2  0.156766 -0.062494  ...  0.059373 -0.051881 -0.039299 -0.171386  0.066677   \n",
              "3  0.046015 -0.152144  ... -0.008471  0.026831 -0.063509 -0.168682 -0.137628   \n",
              "4 -0.067806  0.017086  ... -0.098829  0.037679  0.105494  0.014183 -0.011838   \n",
              "\n",
              "       d124      d125      d126      d127      d128  \n",
              "0  0.081781 -0.102319 -0.015848 -0.165077  0.072695  \n",
              "1  0.148022 -0.073004 -0.174536 -0.090798 -0.089854  \n",
              "2  0.129493 -0.169326 -0.052836 -0.100826 -0.097579  \n",
              "3  0.096271 -0.109646  0.036716 -0.198027  0.030743  \n",
              "4  0.053571  0.031440 -0.030806 -0.126419 -0.033699  \n",
              "\n",
              "[5 rows x 132 columns]"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>d1</th>\n",
              "      <th>d2</th>\n",
              "      <th>d3</th>\n",
              "      <th>d4</th>\n",
              "      <th>d5</th>\n",
              "      <th>d6</th>\n",
              "      <th>d7</th>\n",
              "      <th>d8</th>\n",
              "      <th>d9</th>\n",
              "      <th>...</th>\n",
              "      <th>d119</th>\n",
              "      <th>d120</th>\n",
              "      <th>d121</th>\n",
              "      <th>d122</th>\n",
              "      <th>d123</th>\n",
              "      <th>d124</th>\n",
              "      <th>d125</th>\n",
              "      <th>d126</th>\n",
              "      <th>d127</th>\n",
              "      <th>d128</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-0.032010</td>\n",
              "      <td>-0.194556</td>\n",
              "      <td>0.026390</td>\n",
              "      <td>-0.043677</td>\n",
              "      <td>-0.000813</td>\n",
              "      <td>0.013183</td>\n",
              "      <td>0.023889</td>\n",
              "      <td>-0.060251</td>\n",
              "      <td>-0.161664</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.066293</td>\n",
              "      <td>-0.032030</td>\n",
              "      <td>-0.055601</td>\n",
              "      <td>-0.026373</td>\n",
              "      <td>-0.106818</td>\n",
              "      <td>0.066625</td>\n",
              "      <td>-0.068454</td>\n",
              "      <td>0.047646</td>\n",
              "      <td>-0.167963</td>\n",
              "      <td>0.019028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>-0.094256</td>\n",
              "      <td>-0.036497</td>\n",
              "      <td>0.047269</td>\n",
              "      <td>-0.064922</td>\n",
              "      <td>0.000554</td>\n",
              "      <td>0.024355</td>\n",
              "      <td>0.164749</td>\n",
              "      <td>0.038112</td>\n",
              "      <td>-0.143697</td>\n",
              "      <td>...</td>\n",
              "      <td>0.111077</td>\n",
              "      <td>0.164029</td>\n",
              "      <td>0.039855</td>\n",
              "      <td>-0.170497</td>\n",
              "      <td>0.129083</td>\n",
              "      <td>0.166501</td>\n",
              "      <td>-0.052893</td>\n",
              "      <td>-0.000020</td>\n",
              "      <td>-0.219572</td>\n",
              "      <td>0.054069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.041128</td>\n",
              "      <td>-0.183823</td>\n",
              "      <td>-0.072680</td>\n",
              "      <td>0.025662</td>\n",
              "      <td>0.021938</td>\n",
              "      <td>-0.021193</td>\n",
              "      <td>-0.029180</td>\n",
              "      <td>-0.068742</td>\n",
              "      <td>-0.166934</td>\n",
              "      <td>...</td>\n",
              "      <td>0.032826</td>\n",
              "      <td>0.152789</td>\n",
              "      <td>0.021623</td>\n",
              "      <td>-0.144050</td>\n",
              "      <td>-0.063939</td>\n",
              "      <td>0.151730</td>\n",
              "      <td>-0.056497</td>\n",
              "      <td>-0.005103</td>\n",
              "      <td>-0.207697</td>\n",
              "      <td>0.043618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>-0.216184</td>\n",
              "      <td>-0.177013</td>\n",
              "      <td>0.062658</td>\n",
              "      <td>0.120909</td>\n",
              "      <td>-0.101238</td>\n",
              "      <td>-0.041775</td>\n",
              "      <td>0.086837</td>\n",
              "      <td>-0.085790</td>\n",
              "      <td>-0.322910</td>\n",
              "      <td>...</td>\n",
              "      <td>0.046202</td>\n",
              "      <td>0.023517</td>\n",
              "      <td>0.194948</td>\n",
              "      <td>-0.001575</td>\n",
              "      <td>0.068918</td>\n",
              "      <td>0.193064</td>\n",
              "      <td>-0.073385</td>\n",
              "      <td>0.010638</td>\n",
              "      <td>-0.077569</td>\n",
              "      <td>0.052398</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.093733</td>\n",
              "      <td>-0.146037</td>\n",
              "      <td>-0.084921</td>\n",
              "      <td>0.064993</td>\n",
              "      <td>-0.000117</td>\n",
              "      <td>0.053599</td>\n",
              "      <td>0.028582</td>\n",
              "      <td>-0.005578</td>\n",
              "      <td>-0.025972</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.051806</td>\n",
              "      <td>0.043412</td>\n",
              "      <td>-0.055405</td>\n",
              "      <td>-0.075590</td>\n",
              "      <td>-0.002440</td>\n",
              "      <td>0.186403</td>\n",
              "      <td>-0.085986</td>\n",
              "      <td>-0.120038</td>\n",
              "      <td>-0.175069</td>\n",
              "      <td>0.001805</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 129 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id        d1        d2        d3        d4        d5        d6        d7  \\\n",
              "0   0 -0.032010 -0.194556  0.026390 -0.043677 -0.000813  0.013183  0.023889   \n",
              "1   1 -0.094256 -0.036497  0.047269 -0.064922  0.000554  0.024355  0.164749   \n",
              "2   2  0.041128 -0.183823 -0.072680  0.025662  0.021938 -0.021193 -0.029180   \n",
              "3   3 -0.216184 -0.177013  0.062658  0.120909 -0.101238 -0.041775  0.086837   \n",
              "4   4  0.093733 -0.146037 -0.084921  0.064993 -0.000117  0.053599  0.028582   \n",
              "\n",
              "         d8        d9  ...      d119      d120      d121      d122      d123  \\\n",
              "0 -0.060251 -0.161664  ... -0.066293 -0.032030 -0.055601 -0.026373 -0.106818   \n",
              "1  0.038112 -0.143697  ...  0.111077  0.164029  0.039855 -0.170497  0.129083   \n",
              "2 -0.068742 -0.166934  ...  0.032826  0.152789  0.021623 -0.144050 -0.063939   \n",
              "3 -0.085790 -0.322910  ...  0.046202  0.023517  0.194948 -0.001575  0.068918   \n",
              "4 -0.005578 -0.025972  ... -0.051806  0.043412 -0.055405 -0.075590 -0.002440   \n",
              "\n",
              "       d124      d125      d126      d127      d128  \n",
              "0  0.066625 -0.068454  0.047646 -0.167963  0.019028  \n",
              "1  0.166501 -0.052893 -0.000020 -0.219572  0.054069  \n",
              "2  0.151730 -0.056497 -0.005103 -0.207697  0.043618  \n",
              "3  0.193064 -0.073385  0.010638 -0.077569  0.052398  \n",
              "4  0.186403 -0.085986 -0.120038 -0.175069  0.001805  \n",
              "\n",
              "[5 rows x 129 columns]"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Separate features and labels\n",
        "X_train = train_data.drop(['Id', 'speaker_id', 'gender', 'age'], axis=1)\n",
        "y_train = train_data['speaker_id']\n",
        "\n",
        "# Split the training data into a training set and a validation set\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# # Define the models\n",
        "# linear_svc = LinearSVC(C = 10.0, random_state=42)\n",
        "# lgbm = lgb.LGBMClassifier(random_state=42)\n",
        "\n",
        "# # Train the LinearSVC\n",
        "# linear_svc.fit(X_train, y_train)\n",
        "\n",
        "# # Make predictions on the validation set\n",
        "# val_predictions_svc = linear_svc.predict(X_val)\n",
        "\n",
        "# # Evaluate the accuracy of the LinearSVC\n",
        "# accuracy_svc = accuracy_score(y_val, val_predictions_svc)\n",
        "# print(f'Accuracy of LinearSVC: {accuracy_svc}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/nyuad/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_1206807/517887494.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Perform grid search on the reduced dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_half\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_half\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Best parameters found\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    836\u001b[0m                     )\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 838\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    839\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    840\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.9/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    439\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Reduce the training data by half for faster grid search\n",
        "train_data_half = train_data.sample(frac=0.5, random_state=42)\n",
        "\n",
        "# Separate features and labels\n",
        "X_half = train_data_half.drop(['Id', 'speaker_id', 'gender', 'age'], axis=1)\n",
        "y_half = train_data_half['speaker_id']\n",
        "\n",
        "# Split the reduced data into a training set and a validation set\n",
        "X_train_half, X_val_half, y_train_half, y_val_half = train_test_split(X_half, y_half, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the model\n",
        "linear_svc = LinearSVC(random_state=42, max_iter=10000)\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],\n",
        "    'class_weight': [None, 'balanced'],\n",
        "    # 'tol': [1e-4, 1e-3, 1e-2]\n",
        "}\n",
        "\n",
        "# Define the GridSearchCV\n",
        "grid_search = GridSearchCV(linear_svc, param_grid, cv=3, scoring='accuracy', verbose=2, n_jobs=9)\n",
        "\n",
        "# Perform grid search on the reduced dataset\n",
        "grid_search.fit(X_train_half, y_train_half)\n",
        "\n",
        "# Best parameters found\n",
        "best_params = grid_search.best_params_\n",
        "best_score = grid_search.best_score_\n",
        "\n",
        "print(f\"Best parameters: {best_params}\")\n",
        "print(f\"Best cross-validation score: {best_score}\")\n",
        "\n",
        "# Now you can use best_svc to make predictions on your test data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of LinearSVC: 0.9253046088645595\n"
          ]
        }
      ],
      "source": [
        "best_svc = LinearSVC(C=1.0, class_weight='balanced', random_state=42, max_iter=10000)\n",
        "best_svc.fit(X_train, y_train)\n",
        "\n",
        "val_predictions_svc = best_svc.predict(X_val)\n",
        "\n",
        "# Evaluate the accuracy of the LinearSVC\n",
        "accuracy_svc = accuracy_score(y_val, val_predictions_svc)\n",
        "print(f'Accuracy of LinearSVC: {accuracy_svc}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_data_cleaned = test_data.drop(['Id'], axis=1)\n",
        "test_predictions = best_svc.predict(test_data_cleaned)\n",
        "# Create the submission file\n",
        "submission = pd.DataFrame({'Id': test_data['Id'], 'Predicted': test_predictions})\n",
        "submission.to_csv('voice2speakerid/voice2speakerid_solution.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of KNN: 0.9071163694155041\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/nyuad/anaconda3/lib/python3.9/site-packages/sklearn/neighbors/_classification.py:228: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
            "  mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n"
          ]
        }
      ],
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=1)\n",
        "\n",
        "# Train the KNeighborsClassifier\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the validation set\n",
        "val_predictions_knn = knn.predict(X_val)\n",
        "\n",
        "# Evaluate the accuracy of the KNeighborsClassifier\n",
        "accuracy_knn = accuracy_score(y_val, val_predictions_knn)\n",
        "print(f'Accuracy of KNN: {accuracy_knn}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goGyqP7dnRhU"
      },
      "source": [
        "## *Concepts and tools required to complete this task*\n",
        "\n",
        "*   Basics of machine learning\n",
        "*   Classification\n",
        "*   Understanding of *embeddings*\n",
        "*   Critical Thinking\n",
        "*   Scikit-Learn\n",
        "*   Pandas and numpy\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LHJKVeIcXsV"
      },
      "source": [
        "## Rubric\n",
        "\n",
        "- +10 points for logical and reasonable steps to training and testing the models using the techniques taught in the course, and for a well-documented code and evaluation of **at least two models** at least one of which makes the same predictions as submitted on Kaggle\n",
        "- +5 points for proper comments\n",
        "- +5 points for achieving/crossing Baseline A\n",
        "- +5 points for achieving/crossing Baseline B\n",
        "- +10 points for achieving/crossing Baseline C\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPOY_xX60eFB"
      },
      "source": [
        "# Part II: Voice2Gender (30 points)\n",
        "\n",
        "In general, women speak at a higher pitch—about an octave higher than men. An adult woman's average range is from 165 to 255 Hz, while a man's is 85 to 155 Hz. Men's voices are generally deeper. There are many other differences in the voice quality of men and women that make them identifiably different. Identifying the gender from voice is the most fundamental task -- one that is useful in many other downstream tasks.\n",
        "\n",
        "Create a binary classifier which takes in the *d-vector* as input, and is able to predict the *gender* of the speaker as output, as shown in the diagram below:\n",
        "\n",
        "![voice2gender](https://drive.google.com/uc?id=1dyeFlOuqIDcGOXpNsRuf_I-oPI1qxp_D)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lV9TKQoByaD2"
      },
      "source": [
        "## Prompt\n",
        "\n",
        "More concretely, you will use the d-vectors in `voice_forensics_train.csv` to fit at least two models for the prediction of gender from speaker embedding. You will then predict the `gender` as `female` or `male` of the d-vectors in `voice2genderage_test_x.csv` and submit the predictions to Kaggle.\n",
        "\n",
        "We have provided you with a sample file as `voice2gender_solution_sample.csv`. Use the format of that file to submit your predictions.\n",
        "\n",
        "We have provided three baselines on Kaggle based on the `F1` metric which you will need to beat to score full points on this task.\n",
        "\n",
        "For this part, you will submit your code as part of the notebook, and will also submit the `voice2gender_solution.csv` file with your predictions to Brightspace as well as to Kaggle.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "jrHEurDKzb3p"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9560303725940315\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "train_data = pd.read_csv('voice_forensics_train.csv')\n",
        "test_data = pd.read_csv('voice2gender/voice2genderage_test_x.csv')\n",
        "\n",
        "# Convert gender to binary\n",
        "train_data['gender'] = train_data['gender'].map({'female': 0, 'male': 1})\n",
        "\n",
        "# Separate features and target\n",
        "X = train_data.drop(columns=['Id', 'speaker_id', 'gender', 'age'])  # drop non-feature columns\n",
        "y = train_data['gender']\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the feature data\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "# Initialize the logistic regression model\n",
        "log_reg = LogisticRegression(max_iter=100000)\n",
        "\n",
        "# Fit the model on the training data\n",
        "log_reg.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on the validation set\n",
        "y_pred = log_reg.predict(X_val_scaled)\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "\n",
        "print(f'Validation Accuracy: {accuracy}')\n",
        "# Standardize the test data using the same scaler\n",
        "X_test = test_data.drop(columns=['Id'])  # drop the Id column from test set\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Predict on the test set\n",
        "test_predictions = log_reg.predict(X_test_scaled)\n",
        "\n",
        "# Prepare the submission file\n",
        "submission_df = pd.DataFrame({'Id': test_data['Id'], 'Predicted': test_predictions})\n",
        "submission_df['Predicted'] = submission_df['Predicted'].map({0: 'female', 1: 'male'})\n",
        "\n",
        "# # Save the predictions to a CSV file\n",
        "submission_df.to_csv(\"voice2gender/voice2gender_solution.csv\", index=False)\n",
        "\n",
        "\n",
        "\n",
        "############ SOLUTION END #############"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.9696274059685679\n"
          ]
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "train_data = pd.read_csv('voice_forensics_train.csv')\n",
        "test_data = pd.read_csv('voice2gender/voice2genderage_test_x.csv')\n",
        "\n",
        "# Convert 'female' and 'male' to 0 and 1\n",
        "train_data['gender'] = train_data['gender'].map({'female': 0, 'male': 1})\n",
        "\n",
        "# Separate features and target\n",
        "X = train_data.drop(['Id', 'speaker_id', 'gender', 'age'], axis=1)\n",
        "y = train_data['gender']\n",
        "\n",
        "# Split the dataset into the training set and test set\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "# SVM Classifier with RBF Kernel\n",
        "svm = SVC(kernel='rbf', C=1, gamma='auto', class_weight='balanced', random_state=42)\n",
        "\n",
        "# Fit the classifier to the training data\n",
        "svm.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict the labels of the validation set\n",
        "y_pred = svm.predict(X_val_scaled)\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = accuracy_score(y_val, y_pred)\n",
        "print(f'Validation Accuracy: {accuracy}')\n",
        "\n",
        "# Predict on the standardized test set\n",
        "X_test = test_data.drop('Id', axis=1)  # make sure test_df is already loaded and has the same columns as train_df\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "test_predictions = svm.predict(X_test_scaled)\n",
        "\n",
        "# Create the submission file\n",
        "submission_df = pd.DataFrame({'Id': test_data['Id'], 'Predicted': test_predictions})\n",
        "submission_df['Predicted'] = submission_df['Predicted'].map({0: 'female', 1: 'male'})\n",
        "submission_df.to_csv('voice2gender/voice2gender_solution.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N08hHBwwoHHT"
      },
      "source": [
        "## *Concepts and tools required to complete this task*\n",
        "\n",
        "*   Basics of machine learning\n",
        "*   Classification\n",
        "*   Supervised learning\n",
        "*   Understanding of *embeddings*\n",
        "*   Critical Thinking\n",
        "*   Scikit-Learn\n",
        "*   Pandas and numpy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKg1TBlyccH_"
      },
      "source": [
        "## Rubric\n",
        "\n",
        "- +10 points for logical and reasonable steps to training and testing the models using the techniques taught in the course, and for a well-documented code and evaluation of **at least two models** at least one of which makes the same predictions as submitted on Kaggle\n",
        "- +5 points for achieving/crossing Baseline A\n",
        "- +5 points for achieving/crossing Baseline B\n",
        "- +10 points for achieving/crossing Baseline C\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPtzhK-LOJYk"
      },
      "source": [
        "# Part III: Voice2Age (35 points)\n",
        "\n",
        "Because *age* is a continuous variable, this is a regression task. Create a regression model that predicts the *age* of the speaker from their voice *d-vector*.\n",
        "\n",
        "![voice2age](https://drive.google.com/uc?id=1htIuj-fW_LYH4_WZ_3LczOIRldkMt92z)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJEON1z3OPmO"
      },
      "source": [
        "## Prompt\n",
        "\n",
        "More concretely, you will use the features in `voice_forensics_train.csv` to fit at least two models for the estimation of age from speaker embedding. You will then predict the `age` of the speaker corresponding to the given d-vectors in `voice2genderage_test_x.csv` and submit the predictions to Kaggle.\n",
        "\n",
        "We have provided you with a sample file as `voice2age_solution_sample.csv`. Use the format of that file to submit your predictions.\n",
        "\n",
        "We have provided three baselines on Kaggle based on the `RMSE` metric which you will need to beat to score full points on this task.\n",
        "\n",
        "For this part, you will submit your code as part of the notebook, and will also submit the `voice2age_solution.csv` file with your predictions to Brightspace as well as to Kaggle.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "h8fTcF3WOSFG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation RMSE: 8.844834285356397\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "train_data = pd.read_csv('voice_forensics_train.csv')\n",
        "test_data = pd.read_csv('voice2age/voice2genderage_test_x.csv')\n",
        "\n",
        "# Let's assume train_df is your training data and test_df is your test data\n",
        "# And that 'age' is the target variable you're trying to predict\n",
        "\n",
        "# Separate features and target\n",
        "X = train_data.drop(columns=['Id', 'speaker_id', 'gender', 'age'])  # assuming these are the non-feature columns\n",
        "y = train_data['age']\n",
        "\n",
        "# Split the data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# It's usually a good idea to scale the data for SVR\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "svr = SVR(kernel='rbf', C=1.0, gamma='scale')\n",
        "svr.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred_val = svr.predict(X_val_scaled)\n",
        "\n",
        "# # Setting up the parameter grid for grid search\n",
        "# param_grid = {\n",
        "#     'C': [0.1, 1, 10, 100],  # Regularization parameter\n",
        "#     'gamma': ['scale', 'auto'],  # Kernel coefficient\n",
        "#     'epsilon': [0.01, 0.1, 1],  # Epsilon in the epsilon-SVR model\n",
        "# }\n",
        "\n",
        "# # Create a GridSearchCV object\n",
        "# grid_search = GridSearchCV(SVR(kernel='rbf'), param_grid, cv=5, scoring='neg_root_mean_squared_error', verbose=2, n_jobs=10)\n",
        "\n",
        "# # Fit grid_search to the data\n",
        "# grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "# # Get the best estimator\n",
        "# best_svr = grid_search.best_estimator_\n",
        "\n",
        "# # Predicting the validation set results\n",
        "# y_pred_val = best_svr.predict(X_val_scaled)\n",
        "\n",
        "# Calculate the RMSE\n",
        "rmse_val = np.sqrt(mean_squared_error(y_val, y_pred_val))\n",
        "print(f'Validation RMSE: {rmse_val}')\n",
        "\n",
        "# Now predict the ages on the test set\n",
        "X_test = test_data.drop(columns=['Id'])  # assuming test_df has the same columns as X\n",
        "X_test_scaled = scaler.transform(X_test)  # Scale the test data\n",
        "\n",
        "# Predict on the test set using the best estimator\n",
        "test_predictions = svr.predict(X_test_scaled)\n",
        "\n",
        "# Create the submission DataFrame\n",
        "submission_df = pd.DataFrame({\n",
        "    'Id': test_data['Id'],\n",
        "    'Predicted': test_predictions\n",
        "})\n",
        "\n",
        "# Save the predictions to a CSV file\n",
        "submission_path = 'voice2age/voice2age_solution.csv'\n",
        "submission_df.to_csv(submission_path, index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rj_hjQ8OU5m"
      },
      "source": [
        "## *Concepts and tools required to complete this task*\n",
        "\n",
        "*   Basics of machine learning\n",
        "*   Classification versus regression\n",
        "*   Supervised learning\n",
        "*   Understanding of *embeddings*\n",
        "*   Critical Thinking\n",
        "*   Scikit-Learn\n",
        "*   Pandas and numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18Uy9meTOWVL"
      },
      "source": [
        "## Rubric\n",
        "\n",
        "- +10 points for logical and reasonable steps to training and testing the models using the techniques taught in the course, and for a well-documented code and evaluation of **at least two models** at least one of which makes the same predictions as submitted on Kaggle\n",
        "- +5 points for proper comments\n",
        "- +5 points for achieving/crossing Baseline A\n",
        "- +5 points for achieving/crossing Baseline B\n",
        "- +10 points for achieving/crossing Baseline C\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ak90NJYeVaAR"
      },
      "source": [
        "# Final Remarks\n",
        "\n",
        "## Model Selection\n",
        "There are many supervised machine learning models for the task of *classification*, and *regression*: k-nearest neighbours, decision trees, random forests, logistic/linear regression, support vector machines, neural networks, polynomial regression, and so on. Some models are specific to classification, some to regression, and some to both. There are many models to choose from, and for each model, there are **many** parameters to tune your model on. Of course, you can brute force, and try *all* the models in the world, and tune *all* the parameters on *all* the possible values. But that is not just infeasible, but would be result in some heavy overfitting.\n",
        "So how do you choose the right model for a given problem? This is really big question. The ability to choose the right model, the right architecture, and tune the right set of parameters efficiently requires deep understanding of the task at hand, years of practice, and knowledge of the literature.\n",
        "\n",
        "## Embeddings\n",
        "Notice, how across all the tasks, you did not really have to deal with any **\".wav\"** or **\".mp3\"** files, or any sort of audio/speech processing. In fact, if we had not told you that these *embeddings* or *d-vectors* corresponded to voice recordings, or had not provided you with the Coast Guard context, you had no idea of knowing. For you to accomplish the tasks above, all you needed to know was that these vectors of numbers are *features* to be used in your model, very similar to PS9 where your features were unknown. That is precisely the beauty of *embeddings* in general that they abstract out modality related details for a data scientist to just focus on the task of *modeling*. That said, it is also important to acknowledge that many recent machine learning or deep learning models are actually *end-to-end*, and don't use embeddings at all i.e. for example an audio spectrogram goes into the neural network as input, and out comes the prediction. Of course, all of these statements are simplified versions of complex details, understanding of which requires significant domain knowledge.\n",
        "\n",
        "In the context of embeddings though, a wide variety of research is being conducted on what is the best embedding for a given modality and type of data -- the reason why we went from Word2Vec to GLOVE to ELMo to BERT to [RoBERTA](https://arxiv.org/abs/1907.11692) to [GPT-2](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf) and [GPT-3](https://arxiv.org/abs/2005.14165) for textual data. As of end of 2020, BERT, RoBERTA, GPT-2, and GPT-3 are the most common *pre-trained* deep learning based [*language models*](https://en.wikipedia.org/wiki/Language_model) being used for extracting word-embeddings. Figuring out the optimal architecture for extracting embeddings for a given modality is an art in itself -- one that is essential in the building of real world systems such as Alexa or Google Home, but teaching which is, unfortunately, out of the scope of this course. We encourage you to take courses in *deep learning* and *NLP* to learn these methods in detail as a follow-up to this course."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "PUxdctIdxU6B"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
