{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbZsrKBHQeV7"
      },
      "source": [
        "---\n",
        "#Basic Statistical Testing\n",
        "---\n",
        "\n",
        "In this lecture we're going to review some of the basics of statistical testing in python. We're going to talk about hypothesis testing, statistical significance, and using SciPy to run student's t-tests."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBjE5M9y7Ek_"
      },
      "source": [
        "##Hypothesis Testing\n",
        "\n",
        "We use statistics in a lot of different ways in data science. In this lecture, I want to refresh your knowledge of hypothesis testing, which is a core data analysis activity behind experimentation. The goal of hypothesis testing is to determine if two different conditions in an experiment result in different impacts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "XwUEYtbKQeWC"
      },
      "outputs": [],
      "source": [
        "# Let's import our usual numpy and pandas libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Now let's bring in some new libraries from scipy\n",
        "from scipy import stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWdb2Nbl7nvg"
      },
      "source": [
        "Now, Scipy has an interesting collection of libraries for data science and you'll use most or perhaps all of these libraries. It includes NumPy and Pandas, but also plotting libraries such as Matplotlib (which we'll use next), and a number of scientific library functions as well.\n",
        "\n",
        "When we do hypothesis testing, we actually have two statements of interest: the first is our actual explanation, which we call the alternative hypothesis ($H_1$), and the second is that the explanation we have is not sufficient, and we call this the null hypothesis ($H_0$). Our actual testing method is to determine whether the null hypothesis is true or not. If we find that there is a difference between groups, then we can reject the null hypothesis and we accept our alternative.\n",
        "\n",
        "Let's see an example of this using some grade data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "roo7y4BEX7Hn"
      },
      "outputs": [],
      "source": [
        "# Mount the drive.\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# Commenting these lines out since I run the notebook locally."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "g_ahZdYsQeWD",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>student_id</th>\n",
              "      <th>assignment1_grade</th>\n",
              "      <th>assignment1_submission</th>\n",
              "      <th>assignment2_grade</th>\n",
              "      <th>assignment2_submission</th>\n",
              "      <th>assignment3_grade</th>\n",
              "      <th>assignment3_submission</th>\n",
              "      <th>assignment4_grade</th>\n",
              "      <th>assignment4_submission</th>\n",
              "      <th>assignment5_grade</th>\n",
              "      <th>assignment5_submission</th>\n",
              "      <th>assignment6_grade</th>\n",
              "      <th>assignment6_submission</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B73F2C11-70F0-E37D-8B10-1D20AFED50B1</td>\n",
              "      <td>92.733946</td>\n",
              "      <td>2015-11-02 06:55:34.282000000</td>\n",
              "      <td>83.030552</td>\n",
              "      <td>2015-11-09 02:22:58.938000000</td>\n",
              "      <td>67.164441</td>\n",
              "      <td>2015-11-12 08:58:33.998000000</td>\n",
              "      <td>53.011553</td>\n",
              "      <td>2015-11-16 01:21:24.663000000</td>\n",
              "      <td>47.710398</td>\n",
              "      <td>2015-11-20 13:24:59.692000000</td>\n",
              "      <td>38.168318</td>\n",
              "      <td>2015-11-22 18:31:15.934000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>98A0FAE0-A19A-13D2-4BB5-CFBFD94031D1</td>\n",
              "      <td>86.790821</td>\n",
              "      <td>2015-11-29 14:57:44.429000000</td>\n",
              "      <td>86.290821</td>\n",
              "      <td>2015-12-06 17:41:18.449000000</td>\n",
              "      <td>69.772657</td>\n",
              "      <td>2015-12-10 08:54:55.904000000</td>\n",
              "      <td>55.098125</td>\n",
              "      <td>2015-12-13 17:32:30.941000000</td>\n",
              "      <td>49.588313</td>\n",
              "      <td>2015-12-19 23:26:39.285000000</td>\n",
              "      <td>44.629482</td>\n",
              "      <td>2015-12-21 17:07:24.275000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>D0F62040-CEB0-904C-F563-2F8620916C4E</td>\n",
              "      <td>85.512541</td>\n",
              "      <td>2016-01-09 05:36:02.389000000</td>\n",
              "      <td>85.512541</td>\n",
              "      <td>2016-01-09 06:39:44.416000000</td>\n",
              "      <td>68.410033</td>\n",
              "      <td>2016-01-15 20:22:45.882000000</td>\n",
              "      <td>54.728026</td>\n",
              "      <td>2016-01-11 12:41:50.749000000</td>\n",
              "      <td>49.255224</td>\n",
              "      <td>2016-01-11 17:31:12.489000000</td>\n",
              "      <td>44.329701</td>\n",
              "      <td>2016-01-17 16:24:42.765000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>FFDF2B2C-F514-EF7F-6538-A6A53518E9DC</td>\n",
              "      <td>86.030665</td>\n",
              "      <td>2016-04-30 06:50:39.801000000</td>\n",
              "      <td>68.824532</td>\n",
              "      <td>2016-04-30 17:20:38.727000000</td>\n",
              "      <td>61.942079</td>\n",
              "      <td>2016-05-12 07:47:16.326000000</td>\n",
              "      <td>49.553663</td>\n",
              "      <td>2016-05-07 16:09:20.485000000</td>\n",
              "      <td>49.553663</td>\n",
              "      <td>2016-05-24 12:51:18.016000000</td>\n",
              "      <td>44.598297</td>\n",
              "      <td>2016-05-26 08:09:12.058000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5ECBEEB6-F1CE-80AE-3164-E45E99473FB4</td>\n",
              "      <td>64.813800</td>\n",
              "      <td>2015-12-13 17:06:10.750000000</td>\n",
              "      <td>51.491040</td>\n",
              "      <td>2015-12-14 12:25:12.056000000</td>\n",
              "      <td>41.932832</td>\n",
              "      <td>2015-12-29 14:25:22.594000000</td>\n",
              "      <td>36.929549</td>\n",
              "      <td>2015-12-28 01:29:55.901000000</td>\n",
              "      <td>33.236594</td>\n",
              "      <td>2015-12-29 14:46:06.628000000</td>\n",
              "      <td>33.236594</td>\n",
              "      <td>2016-01-05 01:06:59.546000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             student_id  assignment1_grade  \\\n",
              "0  B73F2C11-70F0-E37D-8B10-1D20AFED50B1          92.733946   \n",
              "1  98A0FAE0-A19A-13D2-4BB5-CFBFD94031D1          86.790821   \n",
              "2  D0F62040-CEB0-904C-F563-2F8620916C4E          85.512541   \n",
              "3  FFDF2B2C-F514-EF7F-6538-A6A53518E9DC          86.030665   \n",
              "4  5ECBEEB6-F1CE-80AE-3164-E45E99473FB4          64.813800   \n",
              "\n",
              "          assignment1_submission  assignment2_grade  \\\n",
              "0  2015-11-02 06:55:34.282000000          83.030552   \n",
              "1  2015-11-29 14:57:44.429000000          86.290821   \n",
              "2  2016-01-09 05:36:02.389000000          85.512541   \n",
              "3  2016-04-30 06:50:39.801000000          68.824532   \n",
              "4  2015-12-13 17:06:10.750000000          51.491040   \n",
              "\n",
              "          assignment2_submission  assignment3_grade  \\\n",
              "0  2015-11-09 02:22:58.938000000          67.164441   \n",
              "1  2015-12-06 17:41:18.449000000          69.772657   \n",
              "2  2016-01-09 06:39:44.416000000          68.410033   \n",
              "3  2016-04-30 17:20:38.727000000          61.942079   \n",
              "4  2015-12-14 12:25:12.056000000          41.932832   \n",
              "\n",
              "          assignment3_submission  assignment4_grade  \\\n",
              "0  2015-11-12 08:58:33.998000000          53.011553   \n",
              "1  2015-12-10 08:54:55.904000000          55.098125   \n",
              "2  2016-01-15 20:22:45.882000000          54.728026   \n",
              "3  2016-05-12 07:47:16.326000000          49.553663   \n",
              "4  2015-12-29 14:25:22.594000000          36.929549   \n",
              "\n",
              "          assignment4_submission  assignment5_grade  \\\n",
              "0  2015-11-16 01:21:24.663000000          47.710398   \n",
              "1  2015-12-13 17:32:30.941000000          49.588313   \n",
              "2  2016-01-11 12:41:50.749000000          49.255224   \n",
              "3  2016-05-07 16:09:20.485000000          49.553663   \n",
              "4  2015-12-28 01:29:55.901000000          33.236594   \n",
              "\n",
              "          assignment5_submission  assignment6_grade  \\\n",
              "0  2015-11-20 13:24:59.692000000          38.168318   \n",
              "1  2015-12-19 23:26:39.285000000          44.629482   \n",
              "2  2016-01-11 17:31:12.489000000          44.329701   \n",
              "3  2016-05-24 12:51:18.016000000          44.598297   \n",
              "4  2015-12-29 14:46:06.628000000          33.236594   \n",
              "\n",
              "          assignment6_submission  \n",
              "0  2015-11-22 18:31:15.934000000  \n",
              "1  2015-12-21 17:07:24.275000000  \n",
              "2  2016-01-17 16:24:42.765000000  \n",
              "3  2016-05-26 08:09:12.058000000  \n",
              "4  2016-01-05 01:06:59.546000000  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df=pd.read_csv (\"data/grades.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AvuCIJlsA7JH"
      },
      "source": [
        "If we take a look at the DataFrame's content, we see that we have six different assignments. Let's look at some summary statistics of this DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3J-2CrqiQeWE"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 2315 rows and 13 columns\n"
          ]
        }
      ],
      "source": [
        "print(\"There are {} rows and {} columns\".format(df.shape[0], df.shape[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3OHtwTgBMSz"
      },
      "source": [
        "For the purpose of this lecture, let's divide this population into two groups:\n",
        "\n",
        "1.   \"early finishers\": those who finished the first assignment by the end of December 2015\n",
        "2.   \"late finishers\": those who finished the first assignment after Dec 2015.\n",
        "\n",
        "In order to do so, it would be useful to convert `assignment1_submission` from a regular string to a `DateTime` object. In order to do so we can use pandas' [`to_datetime()`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html) attribute.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rwy7oB1xQeWE",
        "scrolled": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>student_id</th>\n",
              "      <th>assignment1_grade</th>\n",
              "      <th>assignment1_submission</th>\n",
              "      <th>assignment2_grade</th>\n",
              "      <th>assignment2_submission</th>\n",
              "      <th>assignment3_grade</th>\n",
              "      <th>assignment3_submission</th>\n",
              "      <th>assignment4_grade</th>\n",
              "      <th>assignment4_submission</th>\n",
              "      <th>assignment5_grade</th>\n",
              "      <th>assignment5_submission</th>\n",
              "      <th>assignment6_grade</th>\n",
              "      <th>assignment6_submission</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B73F2C11-70F0-E37D-8B10-1D20AFED50B1</td>\n",
              "      <td>92.733946</td>\n",
              "      <td>2015-11-02 06:55:34.282000000</td>\n",
              "      <td>83.030552</td>\n",
              "      <td>2015-11-09 02:22:58.938000000</td>\n",
              "      <td>67.164441</td>\n",
              "      <td>2015-11-12 08:58:33.998000000</td>\n",
              "      <td>53.011553</td>\n",
              "      <td>2015-11-16 01:21:24.663000000</td>\n",
              "      <td>47.710398</td>\n",
              "      <td>2015-11-20 13:24:59.692000000</td>\n",
              "      <td>38.168318</td>\n",
              "      <td>2015-11-22 18:31:15.934000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>98A0FAE0-A19A-13D2-4BB5-CFBFD94031D1</td>\n",
              "      <td>86.790821</td>\n",
              "      <td>2015-11-29 14:57:44.429000000</td>\n",
              "      <td>86.290821</td>\n",
              "      <td>2015-12-06 17:41:18.449000000</td>\n",
              "      <td>69.772657</td>\n",
              "      <td>2015-12-10 08:54:55.904000000</td>\n",
              "      <td>55.098125</td>\n",
              "      <td>2015-12-13 17:32:30.941000000</td>\n",
              "      <td>49.588313</td>\n",
              "      <td>2015-12-19 23:26:39.285000000</td>\n",
              "      <td>44.629482</td>\n",
              "      <td>2015-12-21 17:07:24.275000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5ECBEEB6-F1CE-80AE-3164-E45E99473FB4</td>\n",
              "      <td>64.813800</td>\n",
              "      <td>2015-12-13 17:06:10.750000000</td>\n",
              "      <td>51.491040</td>\n",
              "      <td>2015-12-14 12:25:12.056000000</td>\n",
              "      <td>41.932832</td>\n",
              "      <td>2015-12-29 14:25:22.594000000</td>\n",
              "      <td>36.929549</td>\n",
              "      <td>2015-12-28 01:29:55.901000000</td>\n",
              "      <td>33.236594</td>\n",
              "      <td>2015-12-29 14:46:06.628000000</td>\n",
              "      <td>33.236594</td>\n",
              "      <td>2016-01-05 01:06:59.546000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>D09000A0-827B-C0FF-3433-BF8FF286E15B</td>\n",
              "      <td>71.647278</td>\n",
              "      <td>2015-12-28 04:35:32.836000000</td>\n",
              "      <td>64.052550</td>\n",
              "      <td>2016-01-03 21:05:38.392000000</td>\n",
              "      <td>64.752550</td>\n",
              "      <td>2016-01-07 08:55:43.692000000</td>\n",
              "      <td>57.467295</td>\n",
              "      <td>2016-01-11 00:45:28.706000000</td>\n",
              "      <td>57.467295</td>\n",
              "      <td>2016-01-11 00:54:13.579000000</td>\n",
              "      <td>57.467295</td>\n",
              "      <td>2016-01-20 19:54:46.166000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>C9D51293-BD58-F113-4167-A7C0BAFCB6E5</td>\n",
              "      <td>66.595568</td>\n",
              "      <td>2015-12-25 02:29:28.415000000</td>\n",
              "      <td>52.916454</td>\n",
              "      <td>2015-12-31 01:42:30.046000000</td>\n",
              "      <td>48.344809</td>\n",
              "      <td>2016-01-05 23:34:02.180000000</td>\n",
              "      <td>47.444809</td>\n",
              "      <td>2016-01-02 07:48:42.517000000</td>\n",
              "      <td>37.955847</td>\n",
              "      <td>2016-01-03 21:27:04.266000000</td>\n",
              "      <td>37.955847</td>\n",
              "      <td>2016-01-19 15:24:31.060000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             student_id  assignment1_grade  \\\n",
              "0  B73F2C11-70F0-E37D-8B10-1D20AFED50B1          92.733946   \n",
              "1  98A0FAE0-A19A-13D2-4BB5-CFBFD94031D1          86.790821   \n",
              "4  5ECBEEB6-F1CE-80AE-3164-E45E99473FB4          64.813800   \n",
              "5  D09000A0-827B-C0FF-3433-BF8FF286E15B          71.647278   \n",
              "8  C9D51293-BD58-F113-4167-A7C0BAFCB6E5          66.595568   \n",
              "\n",
              "          assignment1_submission  assignment2_grade  \\\n",
              "0  2015-11-02 06:55:34.282000000          83.030552   \n",
              "1  2015-11-29 14:57:44.429000000          86.290821   \n",
              "4  2015-12-13 17:06:10.750000000          51.491040   \n",
              "5  2015-12-28 04:35:32.836000000          64.052550   \n",
              "8  2015-12-25 02:29:28.415000000          52.916454   \n",
              "\n",
              "          assignment2_submission  assignment3_grade  \\\n",
              "0  2015-11-09 02:22:58.938000000          67.164441   \n",
              "1  2015-12-06 17:41:18.449000000          69.772657   \n",
              "4  2015-12-14 12:25:12.056000000          41.932832   \n",
              "5  2016-01-03 21:05:38.392000000          64.752550   \n",
              "8  2015-12-31 01:42:30.046000000          48.344809   \n",
              "\n",
              "          assignment3_submission  assignment4_grade  \\\n",
              "0  2015-11-12 08:58:33.998000000          53.011553   \n",
              "1  2015-12-10 08:54:55.904000000          55.098125   \n",
              "4  2015-12-29 14:25:22.594000000          36.929549   \n",
              "5  2016-01-07 08:55:43.692000000          57.467295   \n",
              "8  2016-01-05 23:34:02.180000000          47.444809   \n",
              "\n",
              "          assignment4_submission  assignment5_grade  \\\n",
              "0  2015-11-16 01:21:24.663000000          47.710398   \n",
              "1  2015-12-13 17:32:30.941000000          49.588313   \n",
              "4  2015-12-28 01:29:55.901000000          33.236594   \n",
              "5  2016-01-11 00:45:28.706000000          57.467295   \n",
              "8  2016-01-02 07:48:42.517000000          37.955847   \n",
              "\n",
              "          assignment5_submission  assignment6_grade  \\\n",
              "0  2015-11-20 13:24:59.692000000          38.168318   \n",
              "1  2015-12-19 23:26:39.285000000          44.629482   \n",
              "4  2015-12-29 14:46:06.628000000          33.236594   \n",
              "5  2016-01-11 00:54:13.579000000          57.467295   \n",
              "8  2016-01-03 21:27:04.266000000          37.955847   \n",
              "\n",
              "          assignment6_submission  \n",
              "0  2015-11-22 18:31:15.934000000  \n",
              "1  2015-12-21 17:07:24.275000000  \n",
              "4  2016-01-05 01:06:59.546000000  \n",
              "5  2016-01-20 19:54:46.166000000  \n",
              "8  2016-01-19 15:24:31.060000000  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "early_finishers=df[pd.to_datetime(df['assignment1_submission']) < '2016']\n",
        "early_finishers.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvyQeKSgI1gr"
      },
      "source": [
        "Now that you're skilled with pandas, how would you go about getting the late_finishers dataframe?\n",
        "\n",
        "Here's my solution. We know that the dataframe `df` and the `early_finishers` share index values, so we really just want everything in the `df` which is not in `early_finishers`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5BAH2tlQQeWF"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>student_id</th>\n",
              "      <th>assignment1_grade</th>\n",
              "      <th>assignment1_submission</th>\n",
              "      <th>assignment2_grade</th>\n",
              "      <th>assignment2_submission</th>\n",
              "      <th>assignment3_grade</th>\n",
              "      <th>assignment3_submission</th>\n",
              "      <th>assignment4_grade</th>\n",
              "      <th>assignment4_submission</th>\n",
              "      <th>assignment5_grade</th>\n",
              "      <th>assignment5_submission</th>\n",
              "      <th>assignment6_grade</th>\n",
              "      <th>assignment6_submission</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>D0F62040-CEB0-904C-F563-2F8620916C4E</td>\n",
              "      <td>85.512541</td>\n",
              "      <td>2016-01-09 05:36:02.389000000</td>\n",
              "      <td>85.512541</td>\n",
              "      <td>2016-01-09 06:39:44.416000000</td>\n",
              "      <td>68.410033</td>\n",
              "      <td>2016-01-15 20:22:45.882000000</td>\n",
              "      <td>54.728026</td>\n",
              "      <td>2016-01-11 12:41:50.749000000</td>\n",
              "      <td>49.255224</td>\n",
              "      <td>2016-01-11 17:31:12.489000000</td>\n",
              "      <td>44.329701</td>\n",
              "      <td>2016-01-17 16:24:42.765000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>FFDF2B2C-F514-EF7F-6538-A6A53518E9DC</td>\n",
              "      <td>86.030665</td>\n",
              "      <td>2016-04-30 06:50:39.801000000</td>\n",
              "      <td>68.824532</td>\n",
              "      <td>2016-04-30 17:20:38.727000000</td>\n",
              "      <td>61.942079</td>\n",
              "      <td>2016-05-12 07:47:16.326000000</td>\n",
              "      <td>49.553663</td>\n",
              "      <td>2016-05-07 16:09:20.485000000</td>\n",
              "      <td>49.553663</td>\n",
              "      <td>2016-05-24 12:51:18.016000000</td>\n",
              "      <td>44.598297</td>\n",
              "      <td>2016-05-26 08:09:12.058000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3217BE3F-E4B0-C3B6-9F64-462456819CE4</td>\n",
              "      <td>87.498744</td>\n",
              "      <td>2016-03-05 11:05:25.408000000</td>\n",
              "      <td>69.998995</td>\n",
              "      <td>2016-03-09 07:29:52.405000000</td>\n",
              "      <td>55.999196</td>\n",
              "      <td>2016-03-16 22:31:24.316000000</td>\n",
              "      <td>50.399276</td>\n",
              "      <td>2016-03-18 07:19:26.032000000</td>\n",
              "      <td>45.359349</td>\n",
              "      <td>2016-03-19 10:35:41.869000000</td>\n",
              "      <td>45.359349</td>\n",
              "      <td>2016-03-23 14:02:00.987000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>F1CB5AA1-B3DE-5460-FAFF-BE951FD38B5F</td>\n",
              "      <td>80.576090</td>\n",
              "      <td>2016-01-24 18:24:25.619000000</td>\n",
              "      <td>72.518481</td>\n",
              "      <td>2016-01-27 13:37:12.943000000</td>\n",
              "      <td>65.266633</td>\n",
              "      <td>2016-01-30 14:34:36.581000000</td>\n",
              "      <td>65.266633</td>\n",
              "      <td>2016-02-03 22:08:49.002000000</td>\n",
              "      <td>65.266633</td>\n",
              "      <td>2016-02-16 14:22:23.664000000</td>\n",
              "      <td>65.266633</td>\n",
              "      <td>2016-02-18 08:35:04.796000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>E2C617C2-4654-622C-AB50-1550C4BE42A0</td>\n",
              "      <td>59.270882</td>\n",
              "      <td>2016-03-06 12:06:26.185000000</td>\n",
              "      <td>59.270882</td>\n",
              "      <td>2016-03-13 02:07:25.289000000</td>\n",
              "      <td>53.343794</td>\n",
              "      <td>2016-03-17 07:30:09.241000000</td>\n",
              "      <td>53.343794</td>\n",
              "      <td>2016-03-20 21:45:56.229000000</td>\n",
              "      <td>42.675035</td>\n",
              "      <td>2016-03-27 15:55:04.414000000</td>\n",
              "      <td>38.407532</td>\n",
              "      <td>2016-03-30 20:33:13.554000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             student_id  assignment1_grade  \\\n",
              "2  D0F62040-CEB0-904C-F563-2F8620916C4E          85.512541   \n",
              "3  FFDF2B2C-F514-EF7F-6538-A6A53518E9DC          86.030665   \n",
              "6  3217BE3F-E4B0-C3B6-9F64-462456819CE4          87.498744   \n",
              "7  F1CB5AA1-B3DE-5460-FAFF-BE951FD38B5F          80.576090   \n",
              "9  E2C617C2-4654-622C-AB50-1550C4BE42A0          59.270882   \n",
              "\n",
              "          assignment1_submission  assignment2_grade  \\\n",
              "2  2016-01-09 05:36:02.389000000          85.512541   \n",
              "3  2016-04-30 06:50:39.801000000          68.824532   \n",
              "6  2016-03-05 11:05:25.408000000          69.998995   \n",
              "7  2016-01-24 18:24:25.619000000          72.518481   \n",
              "9  2016-03-06 12:06:26.185000000          59.270882   \n",
              "\n",
              "          assignment2_submission  assignment3_grade  \\\n",
              "2  2016-01-09 06:39:44.416000000          68.410033   \n",
              "3  2016-04-30 17:20:38.727000000          61.942079   \n",
              "6  2016-03-09 07:29:52.405000000          55.999196   \n",
              "7  2016-01-27 13:37:12.943000000          65.266633   \n",
              "9  2016-03-13 02:07:25.289000000          53.343794   \n",
              "\n",
              "          assignment3_submission  assignment4_grade  \\\n",
              "2  2016-01-15 20:22:45.882000000          54.728026   \n",
              "3  2016-05-12 07:47:16.326000000          49.553663   \n",
              "6  2016-03-16 22:31:24.316000000          50.399276   \n",
              "7  2016-01-30 14:34:36.581000000          65.266633   \n",
              "9  2016-03-17 07:30:09.241000000          53.343794   \n",
              "\n",
              "          assignment4_submission  assignment5_grade  \\\n",
              "2  2016-01-11 12:41:50.749000000          49.255224   \n",
              "3  2016-05-07 16:09:20.485000000          49.553663   \n",
              "6  2016-03-18 07:19:26.032000000          45.359349   \n",
              "7  2016-02-03 22:08:49.002000000          65.266633   \n",
              "9  2016-03-20 21:45:56.229000000          42.675035   \n",
              "\n",
              "          assignment5_submission  assignment6_grade  \\\n",
              "2  2016-01-11 17:31:12.489000000          44.329701   \n",
              "3  2016-05-24 12:51:18.016000000          44.598297   \n",
              "6  2016-03-19 10:35:41.869000000          45.359349   \n",
              "7  2016-02-16 14:22:23.664000000          65.266633   \n",
              "9  2016-03-27 15:55:04.414000000          38.407532   \n",
              "\n",
              "          assignment6_submission  \n",
              "2  2016-01-17 16:24:42.765000000  \n",
              "3  2016-05-26 08:09:12.058000000  \n",
              "6  2016-03-23 14:02:00.987000000  \n",
              "7  2016-02-18 08:35:04.796000000  \n",
              "9  2016-03-30 20:33:13.554000000  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "late_finishers=df[~df.index.isin(early_finishers.index)]\n",
        "late_finishers.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IgPmYxAmtRV"
      },
      "source": [
        "Let's take a minute and think of all the other ways we could have also done this.\n",
        "\n",
        "1. You could just copy and paste the first projection and change the sign from less than to greater than or equal to. This is ok, but if you decide you want to change the date down the road you have to remember to change it in two places.\n",
        "2. You could also do a join of the dataframe `df` with `early_finishers` - if you do a left join you only keep the items in the left dataframe. This would have been a good answer.\n",
        "3. You also could have written a function that determines if someone is early or late, and then called `.apply()` on the dataframe and added a new column to the dataframe. This is a pretty reasonable answer as well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zROi7sn0ncwP"
      },
      "source": [
        "As you've seen, the pandas DataFrame object has a variety of statistical functions associated with it. If we call the `mean()` function directly on the dataframe, we see that each of the means for the assignments are calculated. Let's compare the means for our two populations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "FzYK9yC5QeWF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "74.94728457024304\n",
            "74.0450648477065\n"
          ]
        }
      ],
      "source": [
        "print(early_finishers['assignment1_grade'].mean())\n",
        "print(late_finishers['assignment1_grade'].mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ah3k1EcoP3V"
      },
      "source": [
        "Ok, these look pretty similar. But, are they the same? Let's say that we have a hypothesis that early finishers perform better than late finisher. In order to test it, we need to see if the two means are considered \"significantly\" different or not.\n",
        "\n",
        "This is where the **students' t-test** comes in. It allows us to form the alternative hypothesis ($H_1$=\"The two means are different\") as well as the null hypothesis ($H_0$=\"The two means are the same\") and then *test the null hypothesis*. As such, we can come to two conclusions:\n",
        "\n",
        "1. *reject the null hypothesis*, i.e. show that the two means are indeed different\n",
        "2. *fail to reject the null hypothesis*.\n",
        "\n",
        "When doing hypothesis testing, we also have to choose a significance level as a threshold for how much of a chance we're willing to accept. This is to say, what is the probability that we will reject the null hypothesis when it is true? This significance level is typically called alpha. For this example, let's use a threshold of 0.05 for our alpha or 5%, which is the most commonly used number but it's really quite arbitrary.\n",
        "\n",
        "The SciPy library contains a number of different [statistical tests](https://docs.scipy.org/doc/scipy/reference/stats.html) some of which form a basis for hypothesis testing. In order to do an independent t-test, we use SciPy's [`ttest_ind()`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html) function. The `ttest_ind()` function returns the t-statistic and a p-value. It's this latter value, the probability, which is most important to us, as it indicates the chance (between 0 and 1) of our null hypothesis being True."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "5XPkfJcGQeWG"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Ttest_indResult(statistic=1.3223540853721598, pvalue=0.18618101101713855)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Let's bring in the ttest_ind function\n",
        "from scipy import stats\n",
        "\n",
        "# Let's run this function with our two populations, looking at the assignment 1 grades\n",
        "stats.ttest_ind(early_finishers['assignment1_grade'], late_finishers['assignment1_grade'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rWCveCeNEzN"
      },
      "source": [
        "So here we see that the probability that the null hypothesis is true is 0.19, which is above our alpha value of 0.05. As such, we *failed to reject the null hypothesis*.\n",
        "\n",
        "The null hypothesis was that the two populations are the same, and we don't have enough certainty in our evidence (because it is greater than alpha) to come to a conclusion to the contrary. *Note that this also doesn't mean that we have proven the populations are the same.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "a22l7G5rQeWH"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ttest_indResult(statistic=1.2514717608216366, pvalue=0.2108889627004424)\n",
            "Ttest_indResult(statistic=1.6133726558705392, pvalue=0.10679998102227867)\n",
            "Ttest_indResult(statistic=0.049671157386456125, pvalue=0.960388729789337)\n",
            "Ttest_indResult(statistic=-0.05279315545404755, pvalue=0.9579012739746492)\n",
            "Ttest_indResult(statistic=-0.11609743352612056, pvalue=0.9075854011989656)\n"
          ]
        }
      ],
      "source": [
        "# Why don't we check the other assignment grades?\n",
        "print(stats.ttest_ind(early_finishers['assignment2_grade'], late_finishers['assignment2_grade']))\n",
        "print(stats.ttest_ind(early_finishers['assignment3_grade'], late_finishers['assignment3_grade']))\n",
        "print(stats.ttest_ind(early_finishers['assignment4_grade'], late_finishers['assignment4_grade']))\n",
        "print(stats.ttest_ind(early_finishers['assignment5_grade'], late_finishers['assignment5_grade']))\n",
        "print(stats.ttest_ind(early_finishers['assignment6_grade'], late_finishers['assignment6_grade']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fgHXHkFOYOI"
      },
      "source": [
        "Ok, so it looks like in this data we do not have enough evidence to suggest the populations differ with respect to grade. Let's take a look at those p-values for a moment though, because they are saying things that can inform experimental design down the road. For instance, one of the assignments, assignment 3, has a p-value around 0.1. This means that if we accepted a level of chance in similarity of 11% this would have been considered statistically significant. As a researcher, this would suggest to me that there is something here worth considering following up on. For instance, if we had a small number of participants (we don't) or if there was something unique about this assignment as it relates to our experiment (whatever it was) then there may be followup experiments we could run."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpKHOBrdk8Q4"
      },
      "source": [
        "P-values have come under fire recently for being insufficient for telling us enough about the interactions which are happening, and two other techniques, confidence intervals and bayesian analyses, are being used more regularly. One issue with p-values is that as you run more tests you are likely to get a value which is statistically significant just by chance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ogKQ-1VrQeWI"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>90</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.567100</td>\n",
              "      <td>0.781043</td>\n",
              "      <td>0.393838</td>\n",
              "      <td>0.581919</td>\n",
              "      <td>0.763398</td>\n",
              "      <td>0.269889</td>\n",
              "      <td>0.360209</td>\n",
              "      <td>0.844134</td>\n",
              "      <td>0.947740</td>\n",
              "      <td>0.374950</td>\n",
              "      <td>...</td>\n",
              "      <td>0.886204</td>\n",
              "      <td>0.827250</td>\n",
              "      <td>0.279040</td>\n",
              "      <td>0.200217</td>\n",
              "      <td>0.978078</td>\n",
              "      <td>0.018792</td>\n",
              "      <td>0.885409</td>\n",
              "      <td>0.808276</td>\n",
              "      <td>0.905506</td>\n",
              "      <td>0.046967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.110776</td>\n",
              "      <td>0.796641</td>\n",
              "      <td>0.299574</td>\n",
              "      <td>0.937844</td>\n",
              "      <td>0.778204</td>\n",
              "      <td>0.040028</td>\n",
              "      <td>0.084418</td>\n",
              "      <td>0.094288</td>\n",
              "      <td>0.135638</td>\n",
              "      <td>0.324500</td>\n",
              "      <td>...</td>\n",
              "      <td>0.781789</td>\n",
              "      <td>0.476162</td>\n",
              "      <td>0.562760</td>\n",
              "      <td>0.352403</td>\n",
              "      <td>0.666630</td>\n",
              "      <td>0.012462</td>\n",
              "      <td>0.579240</td>\n",
              "      <td>0.996160</td>\n",
              "      <td>0.465260</td>\n",
              "      <td>0.751418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.445499</td>\n",
              "      <td>0.328784</td>\n",
              "      <td>0.555929</td>\n",
              "      <td>0.314703</td>\n",
              "      <td>0.902298</td>\n",
              "      <td>0.685417</td>\n",
              "      <td>0.222744</td>\n",
              "      <td>0.286090</td>\n",
              "      <td>0.240504</td>\n",
              "      <td>0.160481</td>\n",
              "      <td>...</td>\n",
              "      <td>0.893050</td>\n",
              "      <td>0.504484</td>\n",
              "      <td>0.564810</td>\n",
              "      <td>0.958745</td>\n",
              "      <td>0.589630</td>\n",
              "      <td>0.388107</td>\n",
              "      <td>0.675017</td>\n",
              "      <td>0.188406</td>\n",
              "      <td>0.068090</td>\n",
              "      <td>0.314795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.186999</td>\n",
              "      <td>0.211178</td>\n",
              "      <td>0.150249</td>\n",
              "      <td>0.831502</td>\n",
              "      <td>0.757596</td>\n",
              "      <td>0.461316</td>\n",
              "      <td>0.701185</td>\n",
              "      <td>0.028163</td>\n",
              "      <td>0.571327</td>\n",
              "      <td>0.503119</td>\n",
              "      <td>...</td>\n",
              "      <td>0.566458</td>\n",
              "      <td>0.044573</td>\n",
              "      <td>0.584139</td>\n",
              "      <td>0.505537</td>\n",
              "      <td>0.652345</td>\n",
              "      <td>0.102802</td>\n",
              "      <td>0.091165</td>\n",
              "      <td>0.855625</td>\n",
              "      <td>0.565393</td>\n",
              "      <td>0.973469</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.168697</td>\n",
              "      <td>0.843332</td>\n",
              "      <td>0.814919</td>\n",
              "      <td>0.199094</td>\n",
              "      <td>0.901533</td>\n",
              "      <td>0.500640</td>\n",
              "      <td>0.142504</td>\n",
              "      <td>0.467241</td>\n",
              "      <td>0.339646</td>\n",
              "      <td>0.417728</td>\n",
              "      <td>...</td>\n",
              "      <td>0.385902</td>\n",
              "      <td>0.105018</td>\n",
              "      <td>0.712415</td>\n",
              "      <td>0.035936</td>\n",
              "      <td>0.739278</td>\n",
              "      <td>0.497347</td>\n",
              "      <td>0.729172</td>\n",
              "      <td>0.462999</td>\n",
              "      <td>0.833294</td>\n",
              "      <td>0.437451</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 100 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         0         1         2         3         4         5         6   \\\n",
              "0  0.567100  0.781043  0.393838  0.581919  0.763398  0.269889  0.360209   \n",
              "1  0.110776  0.796641  0.299574  0.937844  0.778204  0.040028  0.084418   \n",
              "2  0.445499  0.328784  0.555929  0.314703  0.902298  0.685417  0.222744   \n",
              "3  0.186999  0.211178  0.150249  0.831502  0.757596  0.461316  0.701185   \n",
              "4  0.168697  0.843332  0.814919  0.199094  0.901533  0.500640  0.142504   \n",
              "\n",
              "         7         8         9   ...        90        91        92        93  \\\n",
              "0  0.844134  0.947740  0.374950  ...  0.886204  0.827250  0.279040  0.200217   \n",
              "1  0.094288  0.135638  0.324500  ...  0.781789  0.476162  0.562760  0.352403   \n",
              "2  0.286090  0.240504  0.160481  ...  0.893050  0.504484  0.564810  0.958745   \n",
              "3  0.028163  0.571327  0.503119  ...  0.566458  0.044573  0.584139  0.505537   \n",
              "4  0.467241  0.339646  0.417728  ...  0.385902  0.105018  0.712415  0.035936   \n",
              "\n",
              "         94        95        96        97        98        99  \n",
              "0  0.978078  0.018792  0.885409  0.808276  0.905506  0.046967  \n",
              "1  0.666630  0.012462  0.579240  0.996160  0.465260  0.751418  \n",
              "2  0.589630  0.388107  0.675017  0.188406  0.068090  0.314795  \n",
              "3  0.652345  0.102802  0.091165  0.855625  0.565393  0.973469  \n",
              "4  0.739278  0.497347  0.729172  0.462999  0.833294  0.437451  \n",
              "\n",
              "[5 rows x 100 columns]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Lets see a simulation of this. First, let's create a dataframe of 100 columns, each with 100 numbers between 0 and 1\n",
        "df1=pd.DataFrame([np.random.random(100) for x in range(100)])\n",
        "df1.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skAXcvUemhWQ"
      },
      "source": [
        "Pause for a minute and reflect -- do you understand the list comprehension and how I created this DataFrame?\n",
        "\n",
        "You don't have to use a list comprehension to do this, but you should be able to read this and figure out how it works as this is a commonly used approach on web forums."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "DsAu0vbXQeWI"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>90</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.467375</td>\n",
              "      <td>0.263148</td>\n",
              "      <td>0.459955</td>\n",
              "      <td>0.787021</td>\n",
              "      <td>0.529175</td>\n",
              "      <td>0.554542</td>\n",
              "      <td>0.025789</td>\n",
              "      <td>0.036341</td>\n",
              "      <td>0.306165</td>\n",
              "      <td>0.242293</td>\n",
              "      <td>...</td>\n",
              "      <td>0.303917</td>\n",
              "      <td>0.347498</td>\n",
              "      <td>0.867375</td>\n",
              "      <td>0.180730</td>\n",
              "      <td>0.354352</td>\n",
              "      <td>0.071389</td>\n",
              "      <td>0.949731</td>\n",
              "      <td>0.925626</td>\n",
              "      <td>0.091020</td>\n",
              "      <td>0.955486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.830000</td>\n",
              "      <td>0.645734</td>\n",
              "      <td>0.232797</td>\n",
              "      <td>0.200017</td>\n",
              "      <td>0.550347</td>\n",
              "      <td>0.615246</td>\n",
              "      <td>0.306348</td>\n",
              "      <td>0.897222</td>\n",
              "      <td>0.593727</td>\n",
              "      <td>0.568780</td>\n",
              "      <td>...</td>\n",
              "      <td>0.446213</td>\n",
              "      <td>0.000022</td>\n",
              "      <td>0.161915</td>\n",
              "      <td>0.119789</td>\n",
              "      <td>0.810554</td>\n",
              "      <td>0.695570</td>\n",
              "      <td>0.043975</td>\n",
              "      <td>0.508048</td>\n",
              "      <td>0.033290</td>\n",
              "      <td>0.998085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.649112</td>\n",
              "      <td>0.353875</td>\n",
              "      <td>0.336200</td>\n",
              "      <td>0.411060</td>\n",
              "      <td>0.031867</td>\n",
              "      <td>0.551017</td>\n",
              "      <td>0.452063</td>\n",
              "      <td>0.631763</td>\n",
              "      <td>0.114834</td>\n",
              "      <td>0.691712</td>\n",
              "      <td>...</td>\n",
              "      <td>0.260139</td>\n",
              "      <td>0.344919</td>\n",
              "      <td>0.507921</td>\n",
              "      <td>0.397932</td>\n",
              "      <td>0.774288</td>\n",
              "      <td>0.092614</td>\n",
              "      <td>0.455228</td>\n",
              "      <td>0.036959</td>\n",
              "      <td>0.561909</td>\n",
              "      <td>0.856593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.394503</td>\n",
              "      <td>0.569563</td>\n",
              "      <td>0.842140</td>\n",
              "      <td>0.779259</td>\n",
              "      <td>0.882388</td>\n",
              "      <td>0.496112</td>\n",
              "      <td>0.839899</td>\n",
              "      <td>0.039950</td>\n",
              "      <td>0.295744</td>\n",
              "      <td>0.498701</td>\n",
              "      <td>...</td>\n",
              "      <td>0.699278</td>\n",
              "      <td>0.121214</td>\n",
              "      <td>0.903396</td>\n",
              "      <td>0.606076</td>\n",
              "      <td>0.986920</td>\n",
              "      <td>0.879012</td>\n",
              "      <td>0.339516</td>\n",
              "      <td>0.836628</td>\n",
              "      <td>0.039606</td>\n",
              "      <td>0.405938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.336656</td>\n",
              "      <td>0.233226</td>\n",
              "      <td>0.459436</td>\n",
              "      <td>0.738735</td>\n",
              "      <td>0.463224</td>\n",
              "      <td>0.985554</td>\n",
              "      <td>0.563798</td>\n",
              "      <td>0.664995</td>\n",
              "      <td>0.097652</td>\n",
              "      <td>0.513295</td>\n",
              "      <td>...</td>\n",
              "      <td>0.872963</td>\n",
              "      <td>0.732382</td>\n",
              "      <td>0.190057</td>\n",
              "      <td>0.515701</td>\n",
              "      <td>0.479545</td>\n",
              "      <td>0.811149</td>\n",
              "      <td>0.450356</td>\n",
              "      <td>0.698104</td>\n",
              "      <td>0.264875</td>\n",
              "      <td>0.545774</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 100 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         0         1         2         3         4         5         6   \\\n",
              "0  0.467375  0.263148  0.459955  0.787021  0.529175  0.554542  0.025789   \n",
              "1  0.830000  0.645734  0.232797  0.200017  0.550347  0.615246  0.306348   \n",
              "2  0.649112  0.353875  0.336200  0.411060  0.031867  0.551017  0.452063   \n",
              "3  0.394503  0.569563  0.842140  0.779259  0.882388  0.496112  0.839899   \n",
              "4  0.336656  0.233226  0.459436  0.738735  0.463224  0.985554  0.563798   \n",
              "\n",
              "         7         8         9   ...        90        91        92        93  \\\n",
              "0  0.036341  0.306165  0.242293  ...  0.303917  0.347498  0.867375  0.180730   \n",
              "1  0.897222  0.593727  0.568780  ...  0.446213  0.000022  0.161915  0.119789   \n",
              "2  0.631763  0.114834  0.691712  ...  0.260139  0.344919  0.507921  0.397932   \n",
              "3  0.039950  0.295744  0.498701  ...  0.699278  0.121214  0.903396  0.606076   \n",
              "4  0.664995  0.097652  0.513295  ...  0.872963  0.732382  0.190057  0.515701   \n",
              "\n",
              "         94        95        96        97        98        99  \n",
              "0  0.354352  0.071389  0.949731  0.925626  0.091020  0.955486  \n",
              "1  0.810554  0.695570  0.043975  0.508048  0.033290  0.998085  \n",
              "2  0.774288  0.092614  0.455228  0.036959  0.561909  0.856593  \n",
              "3  0.986920  0.879012  0.339516  0.836628  0.039606  0.405938  \n",
              "4  0.479545  0.811149  0.450356  0.698104  0.264875  0.545774  \n",
              "\n",
              "[5 rows x 100 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Ok, let's create a second dataframe\n",
        "df2=pd.DataFrame([np.random.random(100) for x in range(100)])\n",
        "df2.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSWHu0PRpCPg"
      },
      "source": [
        "Are these two DataFrames the same? Maybe a better question is, is a given column inside of df1 the same as the column inside df2?\n",
        "\n",
        "Let's take a look. Let's assume our critical value is 0.1, or the alpha is 10%. Then let's compare each column in `df1` to the same numbered column in `df2`. We'll report when the p-value is less than 10%, which means that we have sufficient evidence to say that the columns are different."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "FevLobm_QeWI"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Col 10 is statistically significantly different at alpha=0.1, pval=0.009589711358292874\n",
            "Col 16 is statistically significantly different at alpha=0.1, pval=0.07816130123296282\n",
            "Col 17 is statistically significantly different at alpha=0.1, pval=0.04931347947833014\n",
            "Col 21 is statistically significantly different at alpha=0.1, pval=0.058010577695205484\n",
            "Col 41 is statistically significantly different at alpha=0.1, pval=0.07591646613002086\n",
            "Col 53 is statistically significantly different at alpha=0.1, pval=0.02251353345024437\n",
            "Col 58 is statistically significantly different at alpha=0.1, pval=0.006596802898284635\n",
            "Col 81 is statistically significantly different at alpha=0.1, pval=0.01786751621090758\n",
            "Col 85 is statistically significantly different at alpha=0.1, pval=0.02765595706980199\n",
            "Total number different was 9, which is 9.0%\n"
          ]
        }
      ],
      "source": [
        "# Let's write this in a function called test_columns\n",
        "def test_columns(alpha=0.1):\n",
        "    # I want to keep track of how many differ\n",
        "    num_diff=0\n",
        "    # And now we can just iterate over the columns\n",
        "    for col in df1.columns:\n",
        "        # we can run out ttest_ind between the two dataframes\n",
        "        teststat,pval=stats.ttest_ind(df1[col],df2[col])\n",
        "        # and we check the pvalue versus the alpha\n",
        "        if pval<=alpha:\n",
        "            # And now we'll just print out if they are different and increment the num_diff\n",
        "            print(\"Col {} is statistically significantly different at alpha={}, pval={}\".format(col,alpha,pval))\n",
        "            num_diff=num_diff+1\n",
        "    # and let's print out some summary stats\n",
        "    print(\"Total number different was {}, which is {}%\".format(num_diff,float(num_diff)/len(df1.columns)*100))\n",
        "\n",
        "# And now lets actually run this\n",
        "test_columns()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wwPnalhs6Fr"
      },
      "source": [
        "Interesting, so we see that there are a bunch of columns that are different! In fact, that number looks a lot like the alpha value we chose. So what's going on - shouldn't all of the columns be the same? Remember that all the ttest does is check if two sets are similar given some level of confidence, in our case, 10%. The more random comparisons you do, the more will just happen to be the same by chance. In this example, we checked 100 columns, so we would expect there to be roughly 10 of them if our alpha was 0.1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "tBQW8sfnQeWJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Col 10 is statistically significantly different at alpha=0.05, pval=0.009589711358292874\n",
            "Col 17 is statistically significantly different at alpha=0.05, pval=0.04931347947833014\n",
            "Col 53 is statistically significantly different at alpha=0.05, pval=0.02251353345024437\n",
            "Col 58 is statistically significantly different at alpha=0.05, pval=0.006596802898284635\n",
            "Col 81 is statistically significantly different at alpha=0.05, pval=0.01786751621090758\n",
            "Col 85 is statistically significantly different at alpha=0.05, pval=0.02765595706980199\n",
            "Total number different was 6, which is 6.0%\n"
          ]
        }
      ],
      "source": [
        "# We can test some other alpha values as well\n",
        "test_columns(0.05)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXSQgxJqtXW0"
      },
      "source": [
        "So, keep this in mind when you are doing statistical tests like the t-test which has a p-value. Understand that this p-value isn't magic, that it's a threshold for you when reporting results and trying to answer your hypothesis. What's a reasonable threshold? That depends on your question, and you need to engage domain experts to better understand what they would consider significant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "pMNfpu8iQeWK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Col 0 is statistically significantly different at alpha=0.1, pval=0.0015613074813677088\n",
            "Col 1 is statistically significantly different at alpha=0.1, pval=0.0003509666027877339\n",
            "Col 2 is statistically significantly different at alpha=0.1, pval=0.00016195511309266658\n",
            "Col 3 is statistically significantly different at alpha=0.1, pval=0.0001633105957447988\n",
            "Col 4 is statistically significantly different at alpha=0.1, pval=0.016341496210788824\n",
            "Col 5 is statistically significantly different at alpha=0.1, pval=0.004731614455866453\n",
            "Col 6 is statistically significantly different at alpha=0.1, pval=1.4510323961708793e-05\n",
            "Col 7 is statistically significantly different at alpha=0.1, pval=0.03208755170966381\n",
            "Col 8 is statistically significantly different at alpha=0.1, pval=0.012191235751458156\n",
            "Col 9 is statistically significantly different at alpha=0.1, pval=0.00010596992941577062\n",
            "Col 10 is statistically significantly different at alpha=0.1, pval=5.395781066274648e-06\n",
            "Col 11 is statistically significantly different at alpha=0.1, pval=0.005121381654855807\n",
            "Col 12 is statistically significantly different at alpha=0.1, pval=0.0012452964239867176\n",
            "Col 13 is statistically significantly different at alpha=0.1, pval=0.0032470274173143705\n",
            "Col 14 is statistically significantly different at alpha=0.1, pval=0.0006615286887792253\n",
            "Col 15 is statistically significantly different at alpha=0.1, pval=0.00011741040557339598\n",
            "Col 16 is statistically significantly different at alpha=0.1, pval=8.399719941826603e-05\n",
            "Col 17 is statistically significantly different at alpha=0.1, pval=0.0007350937611168018\n",
            "Col 18 is statistically significantly different at alpha=0.1, pval=0.0034629322638403542\n",
            "Col 19 is statistically significantly different at alpha=0.1, pval=0.0015549183874847535\n",
            "Col 20 is statistically significantly different at alpha=0.1, pval=0.0018866673420363442\n",
            "Col 21 is statistically significantly different at alpha=0.1, pval=0.0002876438833437565\n",
            "Col 22 is statistically significantly different at alpha=0.1, pval=0.0016502440553384258\n",
            "Col 23 is statistically significantly different at alpha=0.1, pval=0.0002758367653213287\n",
            "Col 24 is statistically significantly different at alpha=0.1, pval=0.000690750404568857\n",
            "Col 25 is statistically significantly different at alpha=0.1, pval=0.005924861268288452\n",
            "Col 26 is statistically significantly different at alpha=0.1, pval=0.0007470512486126248\n",
            "Col 27 is statistically significantly different at alpha=0.1, pval=0.005297055258723735\n",
            "Col 28 is statistically significantly different at alpha=0.1, pval=0.002118213485644839\n",
            "Col 29 is statistically significantly different at alpha=0.1, pval=0.041414671640245065\n",
            "Col 30 is statistically significantly different at alpha=0.1, pval=0.0034110551880239368\n",
            "Col 31 is statistically significantly different at alpha=0.1, pval=0.0008231196376577407\n",
            "Col 32 is statistically significantly different at alpha=0.1, pval=2.712647927795357e-05\n",
            "Col 33 is statistically significantly different at alpha=0.1, pval=0.00202738049420024\n",
            "Col 34 is statistically significantly different at alpha=0.1, pval=0.00025582058254528894\n",
            "Col 35 is statistically significantly different at alpha=0.1, pval=2.5370780294974894e-05\n",
            "Col 36 is statistically significantly different at alpha=0.1, pval=0.00028466767008020996\n",
            "Col 37 is statistically significantly different at alpha=0.1, pval=0.0008737465262837278\n",
            "Col 38 is statistically significantly different at alpha=0.1, pval=0.001879774232074694\n",
            "Col 39 is statistically significantly different at alpha=0.1, pval=1.3561328351472613e-05\n",
            "Col 40 is statistically significantly different at alpha=0.1, pval=0.02050990161203001\n",
            "Col 41 is statistically significantly different at alpha=0.1, pval=0.005226044359954318\n",
            "Col 42 is statistically significantly different at alpha=0.1, pval=0.001463731331295745\n",
            "Col 43 is statistically significantly different at alpha=0.1, pval=0.000274558392952466\n",
            "Col 44 is statistically significantly different at alpha=0.1, pval=3.9031641553672674e-05\n",
            "Col 45 is statistically significantly different at alpha=0.1, pval=0.03505621703967595\n",
            "Col 46 is statistically significantly different at alpha=0.1, pval=0.0003613261822703396\n",
            "Col 47 is statistically significantly different at alpha=0.1, pval=0.00013077781733621406\n",
            "Col 48 is statistically significantly different at alpha=0.1, pval=0.002873557719831186\n",
            "Col 49 is statistically significantly different at alpha=0.1, pval=0.006351619851671445\n",
            "Col 50 is statistically significantly different at alpha=0.1, pval=1.3539262500948554e-06\n",
            "Col 51 is statistically significantly different at alpha=0.1, pval=6.812521164118277e-05\n",
            "Col 52 is statistically significantly different at alpha=0.1, pval=0.0009362034796532575\n",
            "Col 53 is statistically significantly different at alpha=0.1, pval=1.540825624306945e-05\n",
            "Col 54 is statistically significantly different at alpha=0.1, pval=0.0007960744391068226\n",
            "Col 55 is statistically significantly different at alpha=0.1, pval=1.3469846864370714e-05\n",
            "Col 56 is statistically significantly different at alpha=0.1, pval=0.0015214161682500183\n",
            "Col 57 is statistically significantly different at alpha=0.1, pval=0.02211739941294728\n",
            "Col 58 is statistically significantly different at alpha=0.1, pval=0.0008147147936552034\n",
            "Col 59 is statistically significantly different at alpha=0.1, pval=0.010714288705042065\n",
            "Col 60 is statistically significantly different at alpha=0.1, pval=0.008259555073602778\n",
            "Col 61 is statistically significantly different at alpha=0.1, pval=0.00014500639162793612\n",
            "Col 62 is statistically significantly different at alpha=0.1, pval=0.0016344916889320343\n",
            "Col 63 is statistically significantly different at alpha=0.1, pval=0.0003270769396102451\n",
            "Col 64 is statistically significantly different at alpha=0.1, pval=0.0053931835037770055\n",
            "Col 65 is statistically significantly different at alpha=0.1, pval=9.570224884626323e-05\n",
            "Col 66 is statistically significantly different at alpha=0.1, pval=0.0012614592957028413\n",
            "Col 67 is statistically significantly different at alpha=0.1, pval=0.00019281492460369778\n",
            "Col 68 is statistically significantly different at alpha=0.1, pval=0.00012295495114152995\n",
            "Col 69 is statistically significantly different at alpha=0.1, pval=0.009941064499544142\n",
            "Col 70 is statistically significantly different at alpha=0.1, pval=6.965871282687469e-05\n",
            "Col 71 is statistically significantly different at alpha=0.1, pval=0.0002436368941194513\n",
            "Col 72 is statistically significantly different at alpha=0.1, pval=0.003503784998456461\n",
            "Col 73 is statistically significantly different at alpha=0.1, pval=0.00022537151913527723\n",
            "Col 74 is statistically significantly different at alpha=0.1, pval=0.0005892109538174146\n",
            "Col 75 is statistically significantly different at alpha=0.1, pval=1.9815850528994215e-05\n",
            "Col 76 is statistically significantly different at alpha=0.1, pval=5.590425361775933e-05\n",
            "Col 77 is statistically significantly different at alpha=0.1, pval=1.674110589219398e-05\n",
            "Col 78 is statistically significantly different at alpha=0.1, pval=0.0050071474450912165\n",
            "Col 79 is statistically significantly different at alpha=0.1, pval=0.001068494860499463\n",
            "Col 80 is statistically significantly different at alpha=0.1, pval=0.001955308120874771\n",
            "Col 81 is statistically significantly different at alpha=0.1, pval=0.00045020535948990325\n",
            "Col 82 is statistically significantly different at alpha=0.1, pval=0.0021285026446952924\n",
            "Col 83 is statistically significantly different at alpha=0.1, pval=0.006815035619870609\n",
            "Col 84 is statistically significantly different at alpha=0.1, pval=0.008602546524408899\n",
            "Col 85 is statistically significantly different at alpha=0.1, pval=0.014228480786654365\n",
            "Col 87 is statistically significantly different at alpha=0.1, pval=0.012259174053642585\n",
            "Col 88 is statistically significantly different at alpha=0.1, pval=0.003130320102117825\n",
            "Col 89 is statistically significantly different at alpha=0.1, pval=0.00012904926992715783\n",
            "Col 90 is statistically significantly different at alpha=0.1, pval=1.2825269249095056e-07\n",
            "Col 91 is statistically significantly different at alpha=0.1, pval=4.451092173421201e-05\n",
            "Col 92 is statistically significantly different at alpha=0.1, pval=1.1211803174046012e-05\n",
            "Col 93 is statistically significantly different at alpha=0.1, pval=0.0009082491884490298\n",
            "Col 94 is statistically significantly different at alpha=0.1, pval=0.003049869856559678\n",
            "Col 95 is statistically significantly different at alpha=0.1, pval=0.004280543765411861\n",
            "Col 96 is statistically significantly different at alpha=0.1, pval=0.0003184798949472818\n",
            "Col 97 is statistically significantly different at alpha=0.1, pval=5.208896134295829e-05\n",
            "Col 98 is statistically significantly different at alpha=0.1, pval=7.805693319912599e-05\n",
            "Col 99 is statistically significantly different at alpha=0.1, pval=6.719646368529946e-05\n",
            "Total number different was 99, which is 99.0%\n"
          ]
        }
      ],
      "source": [
        "# Just for fun, lets recreate that second dataframe using a non-normal distribution, I'll arbitrarily chose\n",
        "# chi squared\n",
        "df2=pd.DataFrame([np.random.chisquare(df=1,size=100) for x in range(100)])\n",
        "test_columns()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sz179GI6QeWK"
      },
      "source": [
        "Now we see that all or most columns test to be statistically significant at the 10% level.\n",
        "\n",
        "In this lecture, we've discussed just some of the basics of hypothesis testing in Python. I introduced you to the SciPy library, which you can use for the students t-test. We've discussed some of the practical issues which arise from looking for statistical significance. There's much more to learn about hypothesis testing, for instance, there are different tests used, depending on the shape of your data and different ways to report results instead of just p-values such as confidence intervals or bayesian analyses. But this should give you a basic idea of where to start when comparing two populations for differences, which is a common task for data scientists."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
