{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfxvG9AUT4IC"
      },
      "source": [
        "-----\n",
        "#Pandas Series Data Structure\n",
        "-----\n",
        "\n",
        "In this lecture we're going to explore the **pandas Series structure**. By the end of this lecture you should be\n",
        "familiar with how to store and manipulate single dimensional indexed data in the Series object."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gk3PAIkrT4ID"
      },
      "source": [
        "**The series is one of the core data structures in pandas**. You can think of it as a cross between a list and a dictionary.\n",
        "\n",
        "![Series.png](https://drive.google.com/uc?id=1RlS1LIvx_9oaClrnx3hhcGDt7aQBQSq5)\n",
        "\n",
        "The items are all stored in an order and there's labels with which you can retrieve them. An easy way to visualize this is two columns of data. The first is the special index, a lot like keys in a dictionary. While the\n",
        "second is your actual data. It's important to note that the data column has a label of its own and can be retrieved using the `.name` attribute. This is different than with dictionaries and is useful when it comes to\n",
        "merging multiple columns of data. We'll talk about that in the next couple of lectures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "VHiCNJJZT4ID"
      },
      "outputs": [],
      "source": [
        "# Let's import pandas to get started\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kov00YJc0Czw"
      },
      "source": [
        "##Creating Series using lists\n",
        "\n",
        "One of the easiest ways to create a series is to use an array-like object, like a list.\n",
        "\n",
        "When you do this, Pandas automatically assigns an index starting with zero and sets the name of the series to `None`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "rtWKOqPYT4ID"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    Alice\n",
              "1     Jack\n",
              "2    Molly\n",
              "dtype: object"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Let's make a list of the three of students, Alice, Jack, and Molly, all as strings\n",
        "students = [\"Alice\", \"Jack\", \"Molly\"]\n",
        "\n",
        "# Now we just call the Series function in pandas and pass in the students\n",
        "pd.Series(students)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSDUIErd06cj"
      },
      "source": [
        "The result is a Series object. We see here that pandas has automatically identified the type of data in this Series as `object` and set the dtype parameter as such. We also see that the values are indexed with integers, starting at zero.\n",
        "\n",
        "***Why use pandas vs traditional lists***?\n",
        "Pandas stores series values in a typed array using the Numpy library. This offers significant speedup when processing data versus traditional python lists.\n",
        "\n",
        "This is why in the above example, Pandas assigned the Series' `dtype` as `object`. The `dtype` `object` comes from NumPy, it describes the type of element in an `ndarray`. Every element in an `ndarray` must have the same size in bytes. For `int64` and `float64`, they are 8 bytes. But for strings, the length of the string is not fixed. So instead of saving the bytes of strings in the `ndarray` directly, Pandas uses an `object` `ndarray`, which saves pointers to `objects`; because of this the `dtype` of this kind of `ndarray` is `object`.\n",
        "\n",
        "To double check this, let's create a Series from a list of integers this time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "wT9C36S7T4IF"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    1\n",
              "1    2\n",
              "2    3\n",
              "dtype: int64"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Lets create a Series from a list of integers\n",
        "numbers = [1, 2, 3]\n",
        "\n",
        "pd.Series(numbers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hArZRGo3cH7"
      },
      "source": [
        "As expected, Pandas set the type to `int64`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8GDGh3U3vym"
      },
      "source": [
        "## How Pandas handles missing data\n",
        "\n",
        "It is important to know how `numpy` (and thus `pandas`) handles missing data.\n",
        "\n",
        "In Python, we have the `None` type to indicate the lack of data. Pandas does some type conversion in the backend, and uses the type `object` for the underlying array.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "VVx5FnepT4IG"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    Alice\n",
              "1     Jack\n",
              "2     None\n",
              "dtype: object"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Let's recreate our list of students, but leave the last one as a None\n",
        "students = ['Alice', 'Jack', None]\n",
        "# And lets convert this to a series\n",
        "pd.Series(students)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pmif3EoxVHiX"
      },
      "source": [
        "As expected, it returned it as a `None` type. However, if we create a list of numbers, integers or floats, and put in the `None` type, pandas will automatically convert it to a special floating point value designated as `NaN`, which stands for \"Not a Number\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "Z_elrj0aT4IG"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    1.0\n",
              "1    2.0\n",
              "2    NaN\n",
              "dtype: float64"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# So lets create a list with a None value in it\n",
        "numbers = [1, 2, None]\n",
        "# And turn that into a series\n",
        "pd.Series(numbers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gs1Sf9EnVpoP"
      },
      "source": [
        "So, we notice a couple of things:\n",
        "\n",
        "1.   `NaN` is a different value to `None`.\n",
        "2.   Pandas sets the `dytpe` of a series to floating point when the other values are numerical.\n",
        "\n",
        "So, why not just leave it as an integer? Underneath, pandas represents `NaN` as a floating point number, and because integers can be typecast to floats, pandas went and converted our integers to floats.\n",
        "\n",
        "**It is important to stress that `None` and `NaN` while might be used by data scientists in the same way, i.e. to denote missing data, underneath they are NOT represented by pandas in the same way.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "dgYknXAxT4IG"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Lets bring in numpy which allows us to generate an NaN value\n",
        "import numpy as np\n",
        "# NaN is NOT equivilent to None. Try the equality test, the result is False.\n",
        "np.nan == None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxVtd996YLmH"
      },
      "source": [
        "Note: you can't do an equality test of NAN to itself. When you do, the answer is always False."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "fmml1N9kT4IG"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.nan == np.nan\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRCoj5S7YOwE"
      },
      "source": [
        "The reason behind that is that not every `NaN` can be considered to be the same value. In layman terms, `NaN` cannot be equal to itself because `NaN` is the result of a failure, but that failure can happen in multiple ways. The result of one failure cannot be equal to the result of any other failure and unknown values cannot be equal to each other.\n",
        "\n",
        "This is why NumPy developed a special function for this special case, `.isnan()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "14Hm7m6AT4IH"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.isnan(np.nan)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sgkxh41DsXJg"
      },
      "source": [
        "So keep in mind when you see `NaN`, while it's meaning is similar to `None`, it's a numeric value and treated differently for efficiency reasons."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1dcaEA10aaC"
      },
      "source": [
        "##More on creating Series\n",
        "\n",
        "Let's talk more about how pandas' Series can be created. While a list might be a common way to create some play data, you often find that you have to label data that you want to manipulate.\n",
        "\n",
        "As such, a series can be created directly from dictionary data. If you do this, the index is automatically assigned to the keys of the dictionary that you provided and not just incrementing integers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "cMELdRTbT4IH"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Alice      Physics\n",
              "Jack     Chemistry\n",
              "Molly      English\n",
              "dtype: object"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Here's an example using a dictionary with some data of students and their classes.\n",
        "students_scores = {'Alice': 'Physics',\n",
        "                   'Jack': 'Chemistry',\n",
        "                   'Molly': 'English'}\n",
        "\n",
        "s = pd.Series(students_scores)\n",
        "s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBy8mMFT1DIH"
      },
      "source": [
        "Since it was string data, pandas set the data type of the series to `object`.\n",
        "\n",
        "Note also that the index (the first column which we can retreive using the `index` attribute) is also a list of strings set to dtype `object`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Q_z-yIDJT4IH"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Alice', 'Jack', 'Molly'], dtype='object')"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Once the series has been created, we can get the \"index object\" using the `index` attribute.\n",
        "s.index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "od7TnxLftS7D"
      },
      "source": [
        "As you play more with pandas you'll notice that a lot of things are implemented as numpy arrays, and have the dtype value set.\n",
        "\n",
        "This is true of indicies, and here pandas infered that we were using objects for the index.\n",
        "\n",
        "Also, note that the dtype of object is not just for strings, but for arbitrary objects. For example, let's create a more complex type of data, say, a list of tuples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "02ods6r-T4IH"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    (Alice, Brown)\n",
              "1     (Jack, White)\n",
              "2    (Molly, Green)\n",
              "dtype: object"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "students = [(\"Alice\",\"Brown\"), (\"Jack\", \"White\"), (\"Molly\", \"Green\")]\n",
        "pd.Series(students)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vsr2m7OtzBh"
      },
      "source": [
        "As you can see, each of the tuples is stored in the series, and the type is `object`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnYagxxJtBek"
      },
      "source": [
        "You can also separate your index creation from the data by passing in the index as a list explicitly to the series."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "WbwwWBFRT4IH"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Alice      Physics\n",
              "Jack     Chemistry\n",
              "Molly      English\n",
              "dtype: object"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "s = pd.Series(['Physics', 'Chemistry', 'English'], index=['Alice', 'Jack', 'Molly'])\n",
        "s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2_muHR3tJjE"
      },
      "source": [
        "So what happens if your list of values in the index object are not aligned with the keys in your dictionary for creating the series? Well, pandas overrides the automatic creation to favor only the indices values that you provided. So it will ignore from your dictionary all keys which are not in your index, and pandas will add `None` or `NaN` type values for any index value you provide, which is not in your dictionary key list.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "f7nn3ny1T4II"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Alice    Physics\n",
              "Molly    English\n",
              "Sam          NaN\n",
              "dtype: object"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Here's and example. Let's pass in a dictionary of three items, in this case students\n",
        "# and their courses\n",
        "students_scores = {'Alice': 'Physics',\n",
        "                   'Jack': 'Chemistry',\n",
        "                   'Molly': 'English'}\n",
        "\n",
        "# When I create the series object though I'll only ask for an index with three students,\n",
        "# and exclude Jack. You can imagine that this came from a large dictionary and for some\n",
        "# reason you just need this subset of three.\n",
        "s = pd.Series(students_scores, index=['Alice', 'Molly', 'Sam'])\n",
        "s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDMs4df3toya"
      },
      "source": [
        "The result is that the Series object doesn't have Jack in it, even though he was in our original dataset, but it explicitly does have Sam in it as a missing value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ta-QI2Q8T4II"
      },
      "source": [
        "So far, we've explored the pandas Series data structure. You've seen how to create a series from lists and dictionaries, how indicies on data work, and the way that pandas typecasts data including missing values.\n",
        "\n",
        "Next, let's look at how to \"query\" Series objects together."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzVQ42y_LuHu"
      },
      "source": [
        "##Querying Pandas Series\n",
        "\n",
        "A pandas Series can be \"queried\" either by:\n",
        "\n",
        "1.   the index position\n",
        "2.   the index label\n",
        "\n",
        "Note: If you don't explicitly give an index to the series when querying, the position and the label are effectively the same values.\n",
        "\n",
        "There are two Series \"attributes\" that can be used in a query:\n",
        "\n",
        "1.   `iloc`: To query by numeric location (i.e. index position), starting at zero\n",
        "2.   `loc` : To query by the index label\n",
        "\n",
        "Note: Keep in mind that `iloc` and `loc` are not \"methods\", they are \"attributes\". So you don't use parentheses to query them, but square brackets instead, which is called *the indexing operator*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "e_w2hVRfLuHu"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Alice      Physics\n",
              "Jack     Chemistry\n",
              "Molly      English\n",
              "Sam        History\n",
              "dtype: object"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Lets start with an example. We'll use students enrolled in classes coming from a dictionary\n",
        "import pandas as pd\n",
        "students_classes = {'Alice': 'Physics',\n",
        "                   'Jack': 'Chemistry',\n",
        "                   'Molly': 'English',\n",
        "                   'Sam': 'History'}\n",
        "\n",
        "s = pd.Series(students_classes)\n",
        "s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qHw75wrVOZK"
      },
      "source": [
        "So, for this series, if you wanted to see the fourth entry we would we would use the `iloc` attribute with the parameter 3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "yTrILEyRLuHv"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'History'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "s.iloc[3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQO0-C6EVTPJ"
      },
      "source": [
        "If you wanted to see what class Molly has, we would use the `loc` attribute with a parameter of \"Molly\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "fsZ__iMXLuHw"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'English'"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "s.loc['Molly']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1ITGGsNXxuY"
      },
      "source": [
        "Pandas tries to make our code a bit more readable and provides a sort of smart syntax using the indexing operator, `[]`, directly on the series itself. For instance, if you pass in an integer parameter, the operator will behave as if you want it to query via the `iloc` attribute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "-POcV1sKLuHw"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'History'"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "s[3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNsOCPoaYGhN"
      },
      "source": [
        "If you pass in an object, it will query as if you wanted to use the label based `loc` attribute."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "bIbsZ1N2LuHw"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'English'"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "s['Molly']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i938q2iWYXHL"
      },
      "source": [
        "So what do you think will happen if your index is a list of integers?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "JHPsx_KYLuHw"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "99       Physics\n",
              "100    Chemistry\n",
              "101      English\n",
              "102      History\n",
              "dtype: object"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Here's an example using class and their classcode information, where classes are indexed by\n",
        "# classcodes, in the form of integers\n",
        "class_code = {99: 'Physics',\n",
        "              100: 'Chemistry',\n",
        "              101: 'English',\n",
        "              102: 'History'}\n",
        "s = pd.Series(class_code)\n",
        "s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTf7a7TVYzY7"
      },
      "source": [
        "What do you think will happen if we try and call `s[0]`?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "S0NwhnMCLuHw"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "0",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:3803\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/_libs/index.pyx:165\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2263\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2273\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[1;32m/Users/ritinmalhotra/Documents/Applied Data Science/Notebooks/Lecture_8__Pandas_Series_Data_Structure.ipynb Cell 46\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ritinmalhotra/Documents/Applied%20Data%20Science/Notebooks/Lecture_8__Pandas_Series_Data_Structure.ipynb#X63sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m s[\u001b[39m0\u001b[39;49m]\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/series.py:981\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    978\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[1;32m    980\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m--> 981\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[1;32m    983\u001b[0m \u001b[39mif\u001b[39;00m is_hashable(key):\n\u001b[1;32m    984\u001b[0m     \u001b[39m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[1;32m    985\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    986\u001b[0m         \u001b[39m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/series.py:1089\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1086\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[1;32m   1088\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1089\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[1;32m   1090\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39m_get_values_for_loc(\u001b[39mself\u001b[39m, loc, label)\n",
            "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3803\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3804\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3806\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3807\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3809\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3810\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
            "\u001b[0;31mKeyError\u001b[0m: 0"
          ]
        }
      ],
      "source": [
        "s[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JVkAvLBYwnT"
      },
      "source": [
        "So, that didn't call `s.iloc[0]` underneath as one might expect. Instead, it generated a key error. This is because there's no item in the classes list with an index of zero.\n",
        "\n",
        "Here, Pandas can't determine automatically whether you're intending to query by index position or index label. So you need to be careful when using the indexing operator on the Series itself. The safer option is to be more explicit and use the `iloc` or `loc` attributes directly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "G500OJFRLuHw"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Physics'"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Let's give iloc a go\n",
        "s.iloc[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AouBkwZEh6Sv"
      },
      "source": [
        "##Performing operations with Pandas Series\n",
        "\n",
        "Now we know how to get data out of the series, let's talk about working with the data. A common task is to want to consider all of the values inside of a series and do some sort of operation. This could be trying to find a certain number, or aggregating the data or transforming the data in some way."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJfFo3I_iaRU"
      },
      "source": [
        "###Vectorization\n",
        "\n",
        "A typical programmatic approach to this would be to iterate over all the items in the series, and invoke the operation one is interested in. For instance, we could create a Series of integers representing student grades, and just try and get an average grade"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "p7o_IUPqLuHw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "75.0\n"
          ]
        }
      ],
      "source": [
        "grades = pd.Series([90, 80, 70, 60])\n",
        "\n",
        "total = 0\n",
        "for grade in grades:\n",
        "    total+=grade\n",
        "print(total/len(grades))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMYa__eriniR"
      },
      "source": [
        "This works, but it's slow. Modern computers can do many tasks simultaneously, especially, but not only, tasks involving mathematics.\n",
        "\n",
        "Pandas and the underlying numpy libraries support a method of computation called **vectorization**.\n",
        "\n",
        "Vectorization works with most of the functions in the numpy library, including the sum function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "0mf0Zr8pLuHw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "75.0\n"
          ]
        }
      ],
      "source": [
        "# Here's how we would really write the code using the numpy sum method. First we need to import\n",
        "# the numpy module\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "# Then we just call np.sum and pass in an iterable item. In this case, our panda series.\n",
        "total = np.sum(grades)\n",
        "print(total/len(grades))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JoTcTjJWjPd3"
      },
      "source": [
        "Now both of these methods create the same value, but is one actually faster?\n",
        "\n",
        "The Jupyter Notebook has a magic function which can help. But before we go into that, let's first create a large series of random numbers using numpy's `random` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "lDdf9krwLuHw"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    935\n",
              "1    981\n",
              "2    153\n",
              "3    388\n",
              "4    995\n",
              "dtype: int64"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#np.random.randit() takes 3 parameters: min value, max value, number of integers required\n",
        "numbers = pd.Series(np.random.randint(0,1000,10000))\n",
        "\n",
        "# Now lets look at the top five items in that series to make sure they actually seem random. We\n",
        "# can do this with the head() function\n",
        "numbers.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "8AaA6ZPtLuHw"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# We can also verify that length of the series is correct using the len() function\n",
        "len(numbers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oxsBKcgDuVC"
      },
      "source": [
        "###Magic Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DUgIdeKFkpHd"
      },
      "source": [
        "The ipython interpreter has something called \"magic functions\" that begin with a percentage sign. Try typing `%`, and a list of the available magic functions should appear.\n",
        "\n",
        "You could even write your own magic functions too, but that's a little bit outside of the scope of this course. :)\n",
        "\n",
        "There are two types of magic functions:\n",
        "\n",
        "1. **Line magics**: These are similar to command line calls. They start with a single `%` character. Rest of the line is its argument passed without parentheses or quotes. Line magics can be used as an expression and their return value can be assigned to a variable. We won't cover these in this lecture, but you might see them throughout the course\n",
        "\n",
        "2. **Cell magics**: These have a `%%` character prefix. Unlike line magic functions, they can operate on multiple lines below their call, as long as its within the same Jupyter cell.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4du2Eo2RG9IZ"
      },
      "source": [
        "###Cell Magic Function: timeit\n",
        "\n",
        "One very useful cellular magic function is called `timeit`. This function will run our code a few times to determine, on average, how long it takes.\n",
        "\n",
        "Let's run `timeit` with our original iterative code. You can give `timeit` the number of loops that you would like to run. By default, it is 1,000 loops, but I'll ask it to use 100 runs for the sake of time.\n",
        "\n",
        "Note that in order to use a cellular magic function, it has to be the first line in the cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "i3Us-ZAtLuHw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "561 µs ± 80.4 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit -n 100\n",
        "total = 0\n",
        "for number in numbers:\n",
        "    total+=number\n",
        "\n",
        "total/len(numbers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7X4V1P0KIkqC"
      },
      "source": [
        "Not bad. Timeit ran the code and it doesn't seem to take very long at all, just over 1 millisecond per loop. Now let's try with **vectorization**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "cY06gJBXLuHw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "33.2 µs ± 7.9 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit -n 100\n",
        "total = np.sum(numbers)\n",
        "total/len(numbers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxpFkme0JBHS"
      },
      "source": [
        "The speed difference went from milliseconds (1 thousandth of a second) to microseconds (1 millionth of a second). This is a pretty shocking difference in the speed and demonstrates why one should be aware of parallel computing features and start thinking in functional programming terms.\n",
        "\n",
        "Put more simply, *vectorization* is the ability for a computer to execute multiple instructions at once, and with high performance chips, especially graphics cards, you can get dramatic speedups. Modern graphics cards can run thousands of instructions in parallel."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRZdhf-aOBQV"
      },
      "source": [
        "###Broadcasting\n",
        "\n",
        "A related feature in pandas and numpy is called **broadcasting**. With broadcasting, you can apply an operation to every value in the series, changing the series.\n",
        "\n",
        "For instance, if we wanted to increase every random variable by 2, we could do so quickly using the += operator directly on the Series object.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "K6AnBYu9LuHw"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    935\n",
              "1    981\n",
              "2    153\n",
              "3    388\n",
              "4    995\n",
              "dtype: int64"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Let's look at the head of our series\n",
        "numbers.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "c_Ty24reLuHw"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    937\n",
              "1    983\n",
              "2    155\n",
              "3    390\n",
              "4    997\n",
              "dtype: int64"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# And now lets just increase everything in the series by 2\n",
        "numbers+=2\n",
        "numbers.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gi_sQsicNFn"
      },
      "source": [
        "The procedural way of doing this would be to iterate through all of the items in the series and increase the values directly. Pandas does support iterating through a series much like a dictionary, allowing you to unpack values easily."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "JUHEnThqLuHw"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/qs/8nfd6c2x47v00b37yxwrmd8r0000gn/T/ipykernel_74380/2985685285.py:2: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for label, value in numbers.iteritems():\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0     943\n",
              "1     989\n",
              "2     161\n",
              "3     396\n",
              "4    1003\n",
              "dtype: int64"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# We can use the iteritems() function which returns a label and value\n",
        "for label, value in numbers.iteritems():\n",
        "    # now for the item which is returned, lets call set_value()\n",
        "    numbers.loc[label] = value+2\n",
        "# And we can check the result of this computation\n",
        "numbers.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kpb_1fScTfk"
      },
      "source": [
        "The result is the same. Let's take a look at some speed comparisons. First, lets try ten loops using the iterative approach..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "oUIu2CxULuHw"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<magic-timeit>:4: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11.6 ms ± 840 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit -n 10\n",
        "# we'll create a blank new series of items to deal with\n",
        "s = pd.Series(np.random.randint(0,1000,1000))\n",
        "# And we'll just rewrite our loop from above.\n",
        "for label, value in s.iteritems():\n",
        "    s.loc[label]= value+2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wj6IbBFfcipr"
      },
      "source": [
        "Now, let's try that using the broadcasting methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "z2kzBiSJLuHw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The slowest run took 5.67 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "126 µs ± 108 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit -n 10\n",
        "# We need to recreate a series\n",
        "s = pd.Series(np.random.randint(0,1000,1000))\n",
        "# And we just broadcast with +=\n",
        "s+=2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvuPBFAZimou"
      },
      "source": [
        "Not only is it significantly faster, but it's more concise and easier to read. Again, this is because the typical mathematical operations you would expect are vectorized. If interested, the numpy documentation outlines what it takes to create vectorized functions of your own."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZc_PlUmxtli"
      },
      "source": [
        "###Indexing Operators\n",
        "One last note on using the indexing operators to access series data. The `.loc` attribute lets you not only modify data in place, but also add new data as well. If the value you pass in as the index doesn't exist, then a new entry is added. Keep in mind, though, that indices can have mixed types. While it's important to be aware of the typing going on underneath, Pandas will automatically change the underlying NumPy types as appropriate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "TratsREfLuHw"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0            1\n",
              "1            2\n",
              "2            3\n",
              "History    120\n",
              "dtype: int64"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Here's an example using a Series of a few numbers.\n",
        "s = pd.Series([1, 2, 3])\n",
        "\n",
        "# We could add some new value, maybe a university course\n",
        "s.loc['History'] = 120\n",
        "\n",
        "s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzbSEIO1wr2v"
      },
      "source": [
        "We see that mixed types for data values or index labels are no problem for Pandas. Since \"History\" is not in the original list of indices, `s.loc['History']` essentially creates a new element in the series, with the index named \"History\", and the value of 102.\n",
        "\n",
        "Up until now I've shown only examples of a series where the index values were unique. I want to end this lecture by showing an example where index values are not unique, and this makes pandas Series a little different conceptually than, for instance, a relational database."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uB-IZju8e81u"
      },
      "source": [
        "Lets create a Series with students and the courses which they have taken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-EoSTg7LuHw"
      },
      "outputs": [],
      "source": [
        "students_classes = pd.Series({'Alice': 'Physics',\n",
        "                              'Jack': 'Chemistry',\n",
        "                              'Molly': 'English',\n",
        "                              'Sam': 'History'})\n",
        "students_classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmkX8gWtfATA"
      },
      "source": [
        "Now lets create a Series just for some new student Kelly, which lists all of the courses she has taken. We'll set the index to Kelly, and the data to be the names of courses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jg5PDTaCLuHw"
      },
      "outputs": [],
      "source": [
        "kelly_classes = pd.Series(['Philosophy', 'Arts', 'Math'], index=['Kelly', 'Kelly', 'Kelly'])\n",
        "kelly_classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jz2JQgkPfHAR"
      },
      "source": [
        "Finally, we can append all of the data in this new Series to the first using the `.append()` function. This creates a series which has our original people in it as well as all of Kelly's courses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zH2B5SNCLuHw"
      },
      "outputs": [],
      "source": [
        "all_students_classes = students_classes.append(kelly_classes)\n",
        "all_students_classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfZdgigpyuao"
      },
      "source": [
        "There are a couple of important considerations when using `.append()`. First, Pandas will take the series and try to infer the best data types to use. In this example, everything is a string, so there's no problems here. Second, the `.append()` method doesn't actually change the underlying Series objects, it instead returns a new series which is made up of the two appended together. This is a common pattern in pandas - by default returning a new object instead of modifying in place - and one you should come to expect. By printing the original series we can see that that series hasn't changed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RpcBgh3JLuHw"
      },
      "outputs": [],
      "source": [
        "students_classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nvv0RJTPzbeO"
      },
      "source": [
        "Finally, we see that when we query the appended series for \"Kelly\", we don't get a single value, but all her instances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWJKF-WuLuHw"
      },
      "outputs": [],
      "source": [
        "all_students_classes.loc['Kelly']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XZs4-vPLuHw"
      },
      "source": [
        "In this lecture, we focused on one of the primary data types of the Pandas library, the Series. You learned how to query the Series, with `.loc` and `.iloc`, that the Series is an indexed data structure, how to merge two Series objects together with `.append()`, and the importance of vectorization.\n",
        "\n",
        "There are many more methods associated with the Series object that we haven't talked about. But with these basics down, we'll move on to talking about the Panda's two-dimensional data structure, the `DataFrame`. The `DataFrame` is very similar to the series object, but includes multiple columns of data, and is the structure that you'll spend the majority of your time working with when cleaning and aggregating data."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
